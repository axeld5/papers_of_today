id,title,summary,authors,published,author_count
http://arxiv.org/abs/2405.21068v1,Code Pretraining Improves Entity Tracking Abilities of Language Models,"  Recent work has provided indirect evidence that pretraining language models
on code improves the ability of models to track state changes of discourse
entities expressed in natural language. In this work, we systematically test
this claim by comparing pairs of language models on their entity tracking
performance. Critically, the pairs consist of base models and models trained on
top of these base models with additional code data. We extend this analysis to
additionally examine the effect of math training, another highly structured
data type, and alignment tuning, an important step for enhancing the usability
of models. We find clear evidence that models additionally trained on large
amounts of code outperform the base models. On the other hand, we find no
consistent benefit of additional math training or alignment tuning across
various model families.
","['Najoung Kim', 'Sebastian Schuster', 'Shubham Toshniwal']",2024-05-31T17:56:33Z,3
http://arxiv.org/abs/2405.21064v1,"Recurrent neural networks: vanishing and exploding gradients are not the
  end of the story","  Recurrent neural networks (RNNs) notoriously struggle to learn long-term
memories, primarily due to vanishing and exploding gradients. The recent
success of state-space models (SSMs), a subclass of RNNs, to overcome such
difficulties challenges our theoretical understanding. In this paper, we delve
into the optimization challenges of RNNs and discover that, as the memory of a
network increases, changes in its parameters result in increasingly large
output variations, making gradient-based learning highly sensitive, even
without exploding gradients. Our analysis further reveals the importance of the
element-wise recurrence design pattern combined with careful parametrizations
in mitigating this effect. This feature is present in SSMs, as well as in other
architectures, such as LSTMs. Overall, our insights provide a new explanation
for some of the difficulties in gradient-based learning of RNNs and why some
architectures perform better than others.
","['Nicolas Zucchet', 'Antonio Orvieto']",2024-05-31T17:53:00Z,2
http://arxiv.org/abs/2405.21047v1,Grammar-Aligned Decoding,"  Large Language Models (LLMs) struggle with reliably generating highly
structured outputs, such as program code, mathematical formulas, or well-formed
markup. Constrained decoding approaches mitigate this problem by greedily
restricting what tokens an LLM can output at each step to guarantee that the
output matches a given constraint. Specifically, in grammar-constrained
decoding (GCD), the LLM's output must follow a given grammar. In this paper we
demonstrate that GCD techniques (and in general constrained decoding
techniques) can distort the LLM's distribution, leading to outputs that are
grammatical but appear with likelihoods that are not proportional to the ones
given by the LLM, and so ultimately are low-quality. We call the problem of
aligning sampling with a grammar constraint, grammar-aligned decoding (GAD),
and propose adaptive sampling with approximate expected futures (ASAp), a
decoding algorithm that guarantees the output to be grammatical while provably
producing outputs that match the conditional probability of the LLM's
distribution conditioned on the given grammar constraint. Our algorithm uses
prior sample outputs to soundly overapproximate the future grammaticality of
different output prefixes. Our evaluation on code generation and structured NLP
tasks shows how ASAp often produces outputs with higher likelihood (according
to the LLM's distribution) than existing GCD techniques, while still enforcing
the desired grammatical constraints.
","['Kanghee Park', 'Jiayu Wang', 'Taylor Berg-Kirkpatrick', 'Nadia Polikarpova', ""Loris D'Antoni""]",2024-05-31T17:39:15Z,5
http://arxiv.org/abs/2405.21046v1,"Exploratory Preference Optimization: Harnessing Implicit
  Q*-Approximation for Sample-Efficient RLHF","  Reinforcement learning from human feedback (RLHF) has emerged as a central
tool for language model alignment. We consider online exploration in RLHF,
which exploits interactive access to human or AI feedback by deliberately
encouraging the model to produce diverse, maximally informative responses. By
allowing RLHF to confidently stray from the pre-trained model, online
exploration offers the possibility of novel, potentially super-human
capabilities, but its full potential as a paradigm for language model training
has yet to be realized, owing to computational and statistical bottlenecks in
directly adapting existing reinforcement learning techniques. We propose a new
algorithm for online exploration in RLHF, Exploratory Preference Optimization
(XPO), which is simple and practical -- a one-line change to (online) Direct
Preference Optimization (DPO; Rafailov et al., 2023) -- yet enjoys the
strongest known provable guarantees and promising empirical performance. XPO
augments the DPO objective with a novel and principled exploration bonus,
empowering the algorithm to explore outside the support of the initial model
and human feedback data. In theory, we show that XPO is provably
sample-efficient and converges to a near-optimal language model policy under
natural exploration conditions, irrespective of whether the initial model has
good coverage. Our analysis, which builds on the observation that DPO
implicitly performs a form of $Q^{\star}$-approximation (or, Bellman error
minimization), combines previously disparate techniques from language modeling
and theoretical reinforcement learning in a serendipitous fashion through the
perspective of KL-regularized Markov decision processes. Empirically, we find
that XPO is more sample-efficient than non-exploratory DPO variants in a
preliminary evaluation.
","['Tengyang Xie', 'Dylan J. Foster', 'Akshay Krishnamurthy', 'Corby Rosset', 'Ahmed Awadallah', 'Alexander Rakhlin']",2024-05-31T17:39:06Z,6
http://arxiv.org/abs/2405.21030v1,Standards for Belief Representations in LLMs,"  As large language models (LLMs) continue to demonstrate remarkable abilities
across various domains, computer scientists are developing methods to
understand their cognitive processes, particularly concerning how (and if) LLMs
internally represent their beliefs about the world. However, this field
currently lacks a unified theoretical foundation to underpin the study of
belief in LLMs. This article begins filling this gap by proposing adequacy
conditions for a representation in an LLM to count as belief-like. We argue
that, while the project of belief measurement in LLMs shares striking features
with belief measurement as carried out in decision theory and formal
epistemology, it also differs in ways that should change how we measure belief.
Thus, drawing from insights in philosophy and contemporary practices of machine
learning, we establish four criteria that balance theoretical considerations
with practical constraints. Our proposed criteria include accuracy, coherence,
uniformity, and use, which together help lay the groundwork for a comprehensive
understanding of belief representation in LLMs. We draw on empirical work
showing the limitations of using various criteria in isolation to identify
belief representations.
","['Daniel A. Herrmann', 'Benjamin A. Levinstein']",2024-05-31T17:21:52Z,2
http://arxiv.org/abs/2405.20978v1,"Enhancing Noise Robustness of Retrieval-Augmented Language Models with
  Adaptive Adversarial Training","  Large Language Models (LLMs) exhibit substantial capabilities yet encounter
challenges, including hallucination, outdated knowledge, and untraceable
reasoning processes. Retrieval-augmented generation (RAG) has emerged as a
promising solution, integrating knowledge from external databases to mitigate
these challenges. However, inappropriate retrieved passages can potentially
hinder the LLMs' capacity to generate comprehensive and high-quality responses.
Prior RAG studies on the robustness of retrieval noises often confine
themselves to a limited set of noise types, deviating from real-world retrieval
environments and limiting practical applicability. In this study, we initially
investigate retrieval noises and categorize them into three distinct types,
reflecting real-world environments. We analyze the impact of these various
retrieval noises on the robustness of LLMs. Subsequently, we propose a novel
RAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT).
RAAT leverages adaptive adversarial training to dynamically adjust the model's
training process in response to retrieval noises. Concurrently, it employs
multi-task learning to ensure the model's capacity to internally recognize
noisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model
trained using RAAT exhibits significant improvements in F1 and EM scores under
diverse noise conditions. For reproducibility, we release our code and data at:
https://github.com/calubkk/RAAT.
","['Feiteng Fang', 'Yuelin Bai', 'Shiwen Ni', 'Min Yang', 'Xiaojun Chen', 'Ruifeng Xu']",2024-05-31T16:24:53Z,6
http://arxiv.org/abs/2405.20974v1,"SaySelf: Teaching LLMs to Express Confidence with Self-Reflective
  Rationales","  Large language models (LLMs) often generate inaccurate or fabricated
information and generally fail to indicate their confidence, which limits their
broader applications. Previous work elicits confidence from LLMs by direct or
self-consistency prompting, or constructing specific datasets for supervised
finetuning. The prompting-based approaches have inferior performance, and the
training-based approaches are limited to binary or inaccurate group-level
confidence estimates. In this work, we present the advanced SaySelf, a training
framework that teaches LLMs to express more accurate fine-grained confidence
estimates. In addition, beyond the confidence scores, SaySelf initiates the
process of directing LLMs to produce self-reflective rationales that clearly
identify gaps in their parametric knowledge and explain their uncertainty. This
is achieved by using an LLM to automatically summarize the uncertainties in
specific knowledge via natural language. The summarization is based on the
analysis of the inconsistency in multiple sampled reasoning chains, and the
resulting data is utilized for supervised fine-tuning. Moreover, we utilize
reinforcement learning with a meticulously crafted reward function to calibrate
the confidence estimates, motivating LLMs to deliver accurate, high-confidence
predictions and to penalize overconfidence in erroneous outputs. Experimental
results in both in-distribution and out-of-distribution datasets demonstrate
the effectiveness of SaySelf in reducing the confidence calibration error and
maintaining the task performance. We show that the generated self-reflective
rationales are reasonable and can further contribute to the calibration. The
code is made public at \url{https://github.com/xu1868/SaySelf}.
","['Tianyang Xu', 'Shujin Wu', 'Shizhe Diao', 'Xiaoze Liu', 'Xingyao Wang', 'Yangyi Chen', 'Jing Gao']",2024-05-31T16:21:16Z,7
http://arxiv.org/abs/2405.20962v1,Large Language Models are Zero-Shot Next Location Predictors,"  Predicting the locations an individual will visit in the future is crucial
for solving many societal issues like disease diffusion and reduction of
pollution among many others. The models designed to tackle next-location
prediction, however, require a significant amount of individual-level
information to be trained effectively. Such data may be scarce or even
unavailable in some geographic regions or peculiar scenarios (e.g., cold-start
in recommendation systems). Moreover, the design of a next-location predictor
able to generalize or geographically transfer knowledge is still an open
research challenge. Recent advances in natural language processing have led to
a rapid diffusion of Large Language Models (LLMs) which have shown good
generalization and reasoning capabilities. These insights, coupled with the
recent findings that LLMs are rich in geographical knowledge, allowed us to
believe that these models can act as zero-shot next-location predictors. This
paper evaluates the capabilities of many popular LLMs in this role,
specifically Llama, GPT-3.5 and Mistral 7B. After designing a proper prompt, we
tested the models on three real-world mobility datasets. The results show that
LLMs can obtain accuracies up to 32.4%, a significant relative improvement of
over 600% when compared to sophisticated DL models specifically designed for
human mobility. Moreover, we show that other LLMs are unable to perform the
task properly. To prevent positively biased results, we also propose a
framework inspired by other studies to test data contamination. Finally, we
explored the possibility of using LLMs as text-based explainers for
next-location prediction showing that can effectively provide an explanation
for their decision. Notably, 7B models provide more generic, but still
reliable, explanations compared to larger counterparts. Code:
github.com/ssai-trento/LLM-zero-shot-NL
","['Ciro Beneduce', 'Bruno Lepri', 'Massimiliano Luca']",2024-05-31T16:07:33Z,3
http://arxiv.org/abs/2405.20947v1,OR-Bench: An Over-Refusal Benchmark for Large Language Models,"  Large Language Models (LLMs) require careful safety alignment to prevent
malicious outputs. While significant research focuses on mitigating harmful
content generation, the enhanced safety often come with the side effect of
over-refusal, where the LLMs may reject innocuous prompts and become less
helpful. Although the issue of over-refusal has been empirically observed, a
systematic measurement is challenging due to the difficulty of crafting prompts
that appear harmful but are benign. This study proposes a novel method for
automatically generating large-scale sets of ``seemingly toxic prompts''
(benign prompts likely rejected by LLMs). Leveraging this technique, we
introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench
comprises 80,000 seemingly toxic prompts across 10 common rejection categories,
a subset of around 1,000 hard prompts that are challenging even for
state-of-the-art LLMs, and an additional 600 toxic prompts to prevent
indiscriminate responses. We then conduct a comprehensive study to measure the
over-refusal of 25 popular LLMs across 8 model families. Our datasets are
available at https://huggingface.co/datasets/bench-llm/OR-Bench and the
corresponding demo can be found at
https://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can
help the community develop better safety aligned models.
","['Justin Cui', 'Wei-Lin Chiang', 'Ion Stoica', 'Cho-Jui Hsieh']",2024-05-31T15:44:33Z,4
http://arxiv.org/abs/2405.20935v1,"Effective Interplay between Sparsity and Quantization: From Theory to
  Practice","  The increasing size of deep neural networks necessitates effective model
compression to improve computational efficiency and reduce their memory
footprint. Sparsity and quantization are two prominent compression methods that
have individually demonstrated significant reduction in computational and
memory footprints while preserving model accuracy. While effective, the
interplay between these two methods remains an open question. In this paper, we
investigate the interaction between these two methods and assess whether their
combination impacts final model accuracy. We mathematically prove that applying
sparsity before quantization is the optimal sequence for these operations,
minimizing error in computation. Our empirical studies across a wide range of
models, including OPT and Llama model families (125M-8B) and ViT corroborate
these theoretical findings. In addition, through rigorous analysis, we
demonstrate that sparsity and quantization are not orthogonal; their
interaction can significantly harm model accuracy, with quantization error
playing a dominant role in this degradation. Our findings extend to the
efficient deployment of large models in resource-limited compute platforms and
reduce serving cost, offering insights into best practices for applying these
compression methods to maximize efficacy without compromising accuracy.
","['Simla Burcu Harma', 'Ayan Chakraborty', 'Elizaveta Kostenok', 'Danila Mishin', 'Dongho Ha', 'Babak Falsafi', 'Martin Jaggi', 'Ming Liu', 'Yunho Oh', 'Suvinay Subramanian', 'Amir Yazdanbakhsh']",2024-05-31T15:34:13Z,11
http://arxiv.org/abs/2405.20915v1,Fast yet Safe: Early-Exiting with Risk Control,"  Scaling machine learning models significantly improves their performance.
However, such gains come at the cost of inference being slow and
resource-intensive. Early-exit neural networks (EENNs) offer a promising
solution: they accelerate inference by allowing intermediate layers to exit and
produce a prediction early. Yet a fundamental issue with EENNs is how to
determine when to exit without severely degrading performance. In other words,
when is it 'safe' for an EENN to go 'fast'? To address this issue, we
investigate how to adapt frameworks of risk control to EENNs. Risk control
offers a distribution-free, post-hoc solution that tunes the EENN's exiting
mechanism so that exits only occur when the output is of sufficient quality. We
empirically validate our insights on a range of vision and language tasks,
demonstrating that risk control can produce substantial computational savings,
all the while preserving user-specified performance goals.
","['Metod Jazbec', 'Alexander Timans', 'Tin Hadži Veljković', 'Kaspar Sakmann', 'Dan Zhang', 'Christian A. Naesseth', 'Eric Nalisnick']",2024-05-31T15:21:44Z,7
http://arxiv.org/abs/2405.20906v1,"Enhancing Vision Models for Text-Heavy Content Understanding and
  Interaction","  Interacting and understanding with text heavy visual content with multiple
images is a major challenge for traditional vision models. This paper is on
enhancing vision models' capability to comprehend or understand and learn from
images containing a huge amount of textual information from the likes of
textbooks and research papers which contain multiple images like graphs, etc
and tables in them with different types of axes and scales. The approach
involves dataset preprocessing, fine tuning which is by using instructional
oriented data and evaluation. We also built a visual chat application
integrating CLIP for image encoding and a model from the Massive Text Embedding
Benchmark which is developed to consider both textual and visual inputs. An
accuracy of 96.71% was obtained. The aim of the project is to increase and also
enhance the advance vision models' capabilities in understanding complex visual
textual data interconnected data, contributing to multimodal AI.
","['Adithya TG', 'Adithya SK', 'Abhinav R Bharadwaj', 'Abhiram HA', 'Dr. Surabhi Narayan']",2024-05-31T15:17:47Z,5
http://arxiv.org/abs/2405.20902v1,"Preemptive Answer ""Attacks"" on Chain-of-Thought Reasoning","  Large language models (LLMs) showcase impressive reasoning capabilities when
coupled with Chain-of-Thought (CoT) prompting. However, the robustness of this
approach warrants further investigation. In this paper, we introduce a novel
scenario termed preemptive answers, where the LLM obtains an answer before
engaging in reasoning. This situation can arise inadvertently or induced by
malicious users by prompt injection attacks. Experiments reveal that preemptive
answers significantly impair the model's reasoning capability across various
CoT methods and a broad spectrum of datasets. To bolster the robustness of
reasoning, we propose two measures aimed at mitigating this issue to some
extent.
","['Rongwu Xu', 'Zehan Qi', 'Wei Xu']",2024-05-31T15:15:04Z,3
http://arxiv.org/abs/2405.20876v1,"Investigating Calibration and Corruption Robustness of Post-hoc Pruned
  Perception CNNs: An Image Classification Benchmark Study","  Convolutional Neural Networks (CNNs) have achieved state-of-the-art
performance in many computer vision tasks. However, high computational and
storage demands hinder their deployment into resource-constrained environments,
such as embedded devices. Model pruning helps to meet these restrictions by
reducing the model size, while maintaining superior performance. Meanwhile,
safety-critical applications pose more than just resource and performance
constraints. In particular, predictions must not be overly confident, i.e.,
provide properly calibrated uncertainty estimations (proper uncertainty
calibration), and CNNs must be robust against corruptions like naturally
occurring input perturbations (natural corruption robustness). This work
investigates the important trade-off between uncertainty calibration, natural
corruption robustness, and performance for current state-of-research post-hoc
CNN pruning techniques in the context of image classification tasks. Our study
reveals that post-hoc pruning substantially improves the model's uncertainty
calibration, performance, and natural corruption robustness, sparking hope for
safe and robust embedded CNNs.Furthermore, uncertainty calibration and natural
corruption robustness are not mutually exclusive targets under pruning, as
evidenced by the improved safety aspects obtained by post-hoc unstructured
pruning with increasing compression.
","['Pallavi Mitra', 'Gesina Schwalbe', 'Nadja Klein']",2024-05-31T14:52:49Z,3
http://arxiv.org/abs/2405.20867v1,Automatic Channel Pruning for Multi-Head Attention,"  Despite the strong performance of Transformers, their quadratic computation
complexity presents challenges in applying them to vision tasks. Automatic
pruning is one of effective methods for reducing computation complexity without
heuristic approaches. However, directly applying it to multi-head attention is
not straightforward due to channel misalignment. In this paper, we propose an
automatic channel pruning method to take into account the multi-head attention
mechanism. First, we incorporate channel similarity-based weights into the
pruning indicator to preserve more informative channels in each head. Then, we
adjust pruning indicator to enforce removal of channels in equal proportions
across all heads, preventing the channel misalignment. We also add a reweight
module to compensate for information loss resulting from channel removal, and
an effective initialization step for pruning indicator based on difference of
attention between original structure and each channel. Our proposed method can
be used to not only original attention, but also linear attention, which is
more efficient as linear complexity with respect to the number of tokens. On
ImageNet-1K, applying our pruning method to the FLattenTransformer, which
includes both attention mechanisms, shows outperformed accuracy for several
MACs compared with previous state-of-the-art efficient models and pruned
methods. Code will be available soon.
","['Eunho Lee', 'Youngbae Hwang']",2024-05-31T14:47:20Z,2
http://arxiv.org/abs/2405.20859v1,"clembench-2024: A Challenging, Dynamic, Complementary, Multilingual
  Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents","  It has been established in recent work that Large Language Models (LLMs) can
be prompted to ""self-play"" conversational games that probe certain capabilities
(general instruction following, strategic goal orientation, language
understanding abilities), where the resulting interactive game play can be
automatically scored. In this paper, we take one of the proposed frameworks for
setting up such game-play environments, and further test its usefulness as an
evaluation instrument, along a number of dimensions: We show that it can easily
keep up with new developments while avoiding data contamination, we show that
the tests implemented within it are not yet saturated (human performance is
substantially higher than that of even the best models), and we show that it
lends itself to investigating additional questions, such as the impact of the
prompting language on performance. We believe that the approach forms a good
basis for making decisions on model choice for building applied interactive
systems, and perhaps ultimately setting up a closed-loop development
environment of system and simulated evaluator.
","['Anne Beyer', 'Kranti Chalamalasetti', 'Sherzod Hakimov', 'Brielen Madureira', 'Philipp Sadler', 'David Schlangen']",2024-05-31T14:43:31Z,6
http://arxiv.org/abs/2405.20846v1,"Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive
  Multimodal Models","  Image-based advertisements are complex multimodal stimuli that often contain
unusual visual elements and figurative language. Previous research on automatic
ad understanding has reported impressive zero-shot accuracy of contrastive
vision-and-language models (VLMs) on an ad-explanation retrieval task. Here, we
examine the original task setup and show that contrastive VLMs can solve it by
exploiting grounding heuristics. To control for this confound, we introduce
TRADE, a new evaluation test set with adversarial grounded explanations. While
these explanations look implausible to humans, we show that they ""fool"" four
different contrastive VLMs. Our findings highlight the need for an improved
operationalisation of automatic ad understanding that truly evaluates VLMs'
multimodal reasoning abilities. We make our code and TRADE available at
https://github.com/dmg-illc/trade .
","['A. Bavaresco', 'A. Testoni', 'R. Fernández']",2024-05-31T14:31:46Z,3
http://arxiv.org/abs/2405.20838v1,einspace: Searching for Neural Architectures from Fundamental Operations,"  Neural architecture search (NAS) finds high performing networks for a given
task. Yet the results of NAS are fairly prosaic; they did not e.g. create a
shift from convolutional structures to transformers. This is not least because
the search spaces in NAS often aren't diverse enough to include such
transformations a priori. Instead, for NAS to provide greater potential for
fundamental design shifts, we need a novel expressive search space design which
is built from more fundamental operations. To this end, we introduce einspace,
a search space based on a parameterised probabilistic context-free grammar. Our
space is versatile, supporting architectures of various sizes and complexities,
while also containing diverse network operations which allow it to model
convolutions, attention components and more. It contains many existing
competitive architectures, and provides flexibility for discovering new ones.
Using this search space, we perform experiments to find novel architectures as
well as improvements on existing ones on the diverse Unseen NAS datasets. We
show that competitive architectures can be obtained by searching from scratch,
and we consistently find large improvements when initialising the search with
strong baselines. We believe that this work is an important advancement towards
a transformative NAS paradigm where search space expressivity and strategic
search initialisation play key roles.
","['Linus Ericsson', 'Miguel Espinosa', 'Chenhongyi Yang', 'Antreas Antoniou', 'Amos Storkey', 'Shay B. Cohen', 'Steven McDonagh', 'Elliot J. Crowley']",2024-05-31T14:25:45Z,8
http://arxiv.org/abs/2405.20835v1,"Outliers and Calibration Sets have Diminishing Effect on Quantization of
  Modern LLMs","  Post-Training Quantization (PTQ) enhances the efficiency of Large Language
Models (LLMs) by enabling faster operation and compatibility with more
accessible hardware through reduced memory usage, at the cost of small
performance drops. We explore the role of calibration sets in PTQ, specifically
their effect on hidden activations in various notable open-source LLMs.
Calibration sets are crucial for evaluating activation magnitudes and
identifying outliers, which can distort the quantization range and negatively
impact performance. Our analysis reveals a marked contrast in quantization
effectiveness across models. The older OPT model, which much of the
quantization literature is based on, shows significant performance
deterioration and high susceptibility to outliers with varying calibration
sets. In contrast, newer models like Llama-2 7B, Llama-3 8B, Command-R 35B, and
Mistral 7B demonstrate strong robustness, with Mistral 7B showing near-immunity
to outliers and stable activations. These findings suggest a shift in PTQ
strategies might be needed. As advancements in pre-training methods reduce the
relevance of outliers, there is an emerging need to reassess the fundamentals
of current quantization literature. The emphasis should pivot towards
optimizing inference speed, rather than primarily focusing on outlier
preservation, to align with the evolving characteristics of state-of-the-art
LLMs.
","['Davide Paglieri', 'Saurabh Dash', 'Tim Rocktäschel', 'Jack Parker-Holder']",2024-05-31T14:24:33Z,4
http://arxiv.org/abs/2405.20795v1,"InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced
  Visual Understanding","  Accurate visual understanding is imperative for advancing autonomous systems
and intelligent robots. Despite the powerful capabilities of vision-language
models (VLMs) in processing complex visual scenes, precisely recognizing
obscured or ambiguously presented visual elements remains challenging. To
tackle such issues, this paper proposes InsightSee, a multi-agent framework to
enhance VLMs' interpretative capabilities in handling complex visual
understanding scenarios. The framework comprises a description agent, two
reasoning agents, and a decision agent, which are integrated to refine the
process of visual information interpretation. The design of these agents and
the mechanisms by which they can be enhanced in visual information processing
are presented. Experimental results demonstrate that the InsightSee framework
not only boosts performance on specific visual tasks but also retains the
original models' strength. The proposed framework outperforms state-of-the-art
algorithms in 6 out of 9 benchmark tests, with a substantial advancement in
multimodal understanding.
","['Huaxiang Zhang', 'Yaojia Mu', 'Guo-Niu Zhu', 'Zhongxue Gan']",2024-05-31T13:56:55Z,4
http://arxiv.org/abs/2405.20748v1,"OpenTensor: Reproducing Faster Matrix Multiplication Discovering
  Algorithms","  OpenTensor is a reproduction of AlphaTensor, which discovered a new algorithm
that outperforms the state-of-the-art methods for matrix multiplication by Deep
Reinforcement Learning (DRL). While AlphaTensor provides a promising framework
for solving scientific problems, it is really hard to reproduce due to the
massive tricks and lack of source codes. In this paper, we clean up the
algorithm pipeline, clarify the technical details, and make some improvements
to the training process. Computational results show that OpenTensor can
successfully find efficient matrix multiplication algorithms.
","['Yiwen Sun', 'Wenye Li']",2024-05-31T10:30:14Z,2
http://arxiv.org/abs/2405.20727v1,"GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated
  Learning","  With heightened awareness of data privacy protection, Federated Learning (FL)
has attracted widespread attention as a privacy-preserving distributed machine
learning method. However, the distributed nature of federated learning also
provides opportunities for backdoor attacks, where attackers can guide the
model to produce incorrect predictions without affecting the global model
training process.
  This paper introduces a novel defense mechanism against backdoor attacks in
federated learning, named GANcrop. This approach leverages contrastive learning
to deeply explore the disparities between malicious and benign models for
attack identification, followed by the utilization of Generative Adversarial
Networks (GAN) to recover backdoor triggers and implement targeted mitigation
strategies. Experimental findings demonstrate that GANcrop effectively
safeguards against backdoor attacks, particularly in non-IID scenarios, while
maintaining satisfactory model accuracy, showcasing its remarkable defensive
efficacy and practical utility.
","['Xiaoyun Gan', 'Shanyu Gan', 'Taizhi Su', 'Peng Liu']",2024-05-31T09:33:16Z,4
http://arxiv.org/abs/2405.20708v1,FinGen: A Dataset for Argument Generation in Finance,"  Thinking about the future is one of the important activities that people do
in daily life. Futurists also pay a lot of effort into figuring out possible
scenarios for the future. We argue that the exploration of this direction is
still in an early stage in the NLP research. To this end, we propose three
argument generation tasks in the financial application scenario. Our
experimental results show these tasks are still big challenges for
representative generation models. Based on our empirical results, we further
point out several unresolved issues and challenges in this research direction.
","['Chung-Chi Chen', 'Hiroya Takamura', 'Ichiro Kobayashi', 'Yusuke Miyao']",2024-05-31T09:00:43Z,4
http://arxiv.org/abs/2405.20705v1,"ADESSE: Advice Explanations in Complex Repeated Decision-Making
  Environments","  In the evolving landscape of human-centered AI, fostering a synergistic
relationship between humans and AI agents in decision-making processes stands
as a paramount challenge. This work considers a problem setup where an
intelligent agent comprising a neural network-based prediction component and a
deep reinforcement learning component provides advice to a human decision-maker
in complex repeated decision-making environments. Whether the human
decision-maker would follow the agent's advice depends on their beliefs and
trust in the agent and on their understanding of the advice itself. To this
end, we developed an approach named ADESSE to generate explanations about the
adviser agent to improve human trust and decision-making. Computational
experiments on a range of environments with varying model sizes demonstrate the
applicability and scalability of ADESSE. Furthermore, an interactive game-based
user study shows that participants were significantly more satisfied, achieved
a higher reward in the game, and took less time to select an action when
presented with explanations generated by ADESSE. These findings illuminate the
critical role of tailored, human-centered explanations in AI-assisted
decision-making.
","['Sören Schleibaum', 'Lu Feng', 'Sarit Kraus', 'Jörg P. Müller']",2024-05-31T08:59:20Z,4
http://arxiv.org/abs/2405.20701v1,"Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
  for Prompt Enhancement","  Large language models (LLMs) demonstrate exceptional instruct-following
ability to complete various downstream tasks. Although this impressive ability
makes LLMs flexible task solvers, their performance in solving tasks also
heavily relies on instructions. In this paper, we reveal that LLMs are
over-sensitive to lexical variations in task instructions, even when the
variations are imperceptible to humans. By providing models with neighborhood
instructions, which are closely situated in the latent representation space and
differ by only one semantically similar word, the performance on downstream
tasks can be vastly different. Following this property, we propose a black-box
Combinatorial Optimization framework for Prompt Lexical Enhancement (COPLE).
COPLE performs iterative lexical optimization according to the feedback from a
batch of proxy tasks, using a search strategy related to word influence.
Experiments show that even widely-used human-crafted prompts for current
benchmarks suffer from the lexical sensitivity of models, and COPLE recovers
the declined model ability in both instruct-following and solving downstream
tasks.
","['Pengwei Zhan', 'Zhen Xu', 'Qian Tan', 'Jie Song', 'Ru Xie']",2024-05-31T08:53:59Z,5
http://arxiv.org/abs/2405.20687v1,Conditioning GAN Without Training Dataset,"  Deep learning algorithms have a large number of trainable parameters often
with sizes of hundreds of thousands or more. Training this algorithm requires a
large amount of training data and generating a sufficiently large dataset for
these algorithms is costly\cite{noguchi2019image}.
  GANs are generative neural networks that use two deep learning networks that
are competing with each other. The networks are generator and discriminator
networks. The generator tries to generate realistic images which resemble the
actual training dataset by approximating the training data distribution and the
discriminator is trained to classify images as real or
fake(generated)\cite{goodfellow2016nips}. Training these GAN algorithms also
requires a large amount of training dataset\cite{noguchi2019image}.
  In this study, the aim is to address the question, ""Given an unconditioned
pretrained generator network and a pretrained classifier, is it feasible to
develop a conditioned generator without relying on any training dataset?""
  The paper begins with a general introduction to the problem. The subsequent
sections are structured as follows: Section 2 provides background information
on the problem. Section 3 reviews relevant literature on the topic. Section 4
outlines the methodology employed in this study. Section 5 presents the
experimental results. Section 6 discusses the findings and proposes potential
future research directions. Finally, Section 7 offers concluding remarks.
  The implementation can be accessed
\href{https://github.com/kidist-amde/BigGAN-PyTorch}{here}.
",['Kidist Amde Mekonnen'],2024-05-31T08:31:26Z,1
http://arxiv.org/abs/2405.20681v1,No Free Lunch Theorem for Privacy-Preserving LLM Inference,"  Individuals and businesses have been significantly benefited by Large
Language Models (LLMs) including PaLM, Gemini and ChatGPT in various ways. For
example, LLMs enhance productivity, reduce costs, and enable us to focus on
more valuable tasks. Furthermore, LLMs possess the capacity to sift through
extensive datasets, uncover underlying patterns, and furnish critical insights
that propel the frontiers of technology and science. However, LLMs also pose
privacy concerns. Users' interactions with LLMs may expose their sensitive
personal or company information. A lack of robust privacy safeguards and legal
frameworks could permit the unwarranted intrusion or improper handling of
individual data, thereby risking infringements of privacy and the theft of
personal identities. To ensure privacy, it is essential to minimize the
dependency between shared prompts and private information. Various
randomization approaches have been proposed to protect prompts' privacy, but
they may incur utility loss compared to unprotected LLMs prompting. Therefore,
it is essential to evaluate the balance between the risk of privacy leakage and
loss of utility when conducting effective protection mechanisms. The current
study develops a framework for inferring privacy-protected Large Language
Models (LLMs) and lays down a solid theoretical basis for examining the
interplay between privacy preservation and utility. The core insight is
encapsulated within a theorem that is called as the NFL (abbreviation of the
word No-Free-Lunch) Theorem.
","['Xiaojin Zhang', 'Yulin Fei', 'Yan Kang', 'Wei Chen', 'Lixin Fan', 'Hai Jin', 'Qiang Yang']",2024-05-31T08:22:53Z,7
http://arxiv.org/abs/2405.20675v1,Adv-KD: Adversarial Knowledge Distillation for Faster Diffusion Sampling,"  Diffusion Probabilistic Models (DPMs) have emerged as a powerful class of
deep generative models, achieving remarkable performance in image synthesis
tasks. However, these models face challenges in terms of widespread adoption
due to their reliance on sequential denoising steps during sample generation.
This dependence leads to substantial computational requirements, making them
unsuitable for resource-constrained or real-time processing systems. To address
these challenges, we propose a novel method that integrates denoising phases
directly into the model's architecture, thereby reducing the need for
resource-intensive computations. Our approach combines diffusion models with
generative adversarial networks (GANs) through knowledge distillation, enabling
more efficient training and evaluation. By utilizing a pre-trained diffusion
model as a teacher model, we train a student model through adversarial
learning, employing layerwise transformations for denoising and submodules for
predicting the teacher model's output at various points in time. This
integration significantly reduces the number of parameters and denoising steps
required, leading to improved sampling speed at test time. We validate our
method with extensive experiments, demonstrating comparable performance with
reduced computational requirements compared to existing approaches. By enabling
the deployment of diffusion models on resource-constrained devices, our
research mitigates their computational burden and paves the way for wider
accessibility and practical use across the research community and end-users.
  Our code is publicly available at https://github.com/kidist-amde/Adv-KD
","['Kidist Amde Mekonnen', ""Nicola Dall'Asen"", 'Paolo Rota']",2024-05-31T08:19:44Z,3
http://arxiv.org/abs/2405.20653v1,"Enhancing Jailbreak Attack Against Large Language Models through Silent
  Tokens","  Along with the remarkable successes of Language language models, recent
research also started to explore the security threats of LLMs, including
jailbreaking attacks. Attackers carefully craft jailbreaking prompts such that
a target LLM will respond to the harmful question. Existing jailbreaking
attacks require either human experts or leveraging complicated algorithms to
craft jailbreaking prompts. In this paper, we introduce BOOST, a simple attack
that leverages only the eos tokens. We demonstrate that rather than
constructing complicated jailbreaking prompts, the attacker can simply append a
few eos tokens to the end of a harmful question. It will bypass the safety
alignment of LLMs and lead to successful jailbreaking attacks. We further apply
BOOST to four representative jailbreak methods and show that the attack success
rates of these methods can be significantly enhanced by simply adding eos
tokens to the prompt. To understand this simple but novel phenomenon, we
conduct empirical analyses. Our analysis reveals that adding eos tokens makes
the target LLM believe the input is much less harmful, and eos tokens have low
attention values and do not affect LLM's understanding of the harmful
questions, leading the model to actually respond to the questions. Our findings
uncover how fragile an LLM is against jailbreak attacks, motivating the
development of strong safety alignment approaches.
","['Jiahao Yu', 'Haozheng Luo', 'Jerry Yao-Chieh', 'Wenbo Guo', 'Han Liu', 'Xinyu Xing']",2024-05-31T07:41:03Z,6
http://arxiv.org/abs/2405.20643v1,Learning Gaze-aware Compositional GAN,"  Gaze-annotated facial data is crucial for training deep neural networks
(DNNs) for gaze estimation. However, obtaining these data is labor-intensive
and requires specialized equipment due to the challenge of accurately
annotating the gaze direction of a subject. In this work, we present a
generative framework to create annotated gaze data by leveraging the benefits
of labeled and unlabeled data sources. We propose a Gaze-aware Compositional
GAN that learns to generate annotated facial images from a limited labeled
dataset. Then we transfer this model to an unlabeled data domain to take
advantage of the diversity it provides. Experiments demonstrate our approach's
effectiveness in generating within-domain image augmentations in the ETH-XGaze
dataset and cross-domain augmentations in the CelebAMask-HQ dataset domain for
gaze estimation DNN training. We also show additional applications of our work,
which include facial image editing and gaze redirection.
","['Nerea Aranjuelo', 'Siyu Huang', 'Ignacio Arganda-Carreras', 'Luis Unzueta', 'Oihana Otaegui', 'Hanspeter Pfister', 'Donglai Wei']",2024-05-31T07:07:54Z,7
http://arxiv.org/abs/2405.20628v1,"ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in
  Code-Mixed Videos","  In an era of rapidly evolving internet technology, the surge in multimodal
content, including videos, has expanded the horizons of online communication.
However, the detection of toxic content in this diverse landscape, particularly
in low-resource code-mixed languages, remains a critical challenge. While
substantial research has addressed toxic content detection in textual data, the
realm of video content, especially in non-English languages, has been
relatively underexplored. This paper addresses this research gap by introducing
a benchmark dataset, the first of its kind, consisting of 931 videos with 4021
code-mixed Hindi-English utterances collected from YouTube. Each utterance
within this dataset has been meticulously annotated for toxicity, severity, and
sentiment labels. We have developed an advanced Multimodal Multitask framework
built for Toxicity detection in Video Content by leveraging Large Language
Models (LLMs), crafted for the primary objective along with the additional
tasks of conducting sentiment and severity analysis. ToxVidLLM incorporates
three key modules the Encoder module, Cross-Modal Synchronization module, and
Multitask module crafting a generic multimodal LLM customized for intricate
video classification tasks. Our experiments reveal that incorporating multiple
modalities from the videos substantially enhances the performance of toxic
content detection by achieving an Accuracy and Weighted F1 score of 94.29% and
94.35%, respectively.
","['Krishanu Maity', 'A. S. Poornash', 'Sriparna Saha', 'Pushpak Bhattacharyya']",2024-05-31T05:40:56Z,4
http://arxiv.org/abs/2405.20625v1,Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning,"  As the applicability of Large Language Models (LLMs) extends beyond
traditional text processing tasks, there is a burgeoning interest in their
potential to excel in planning and reasoning assignments, realms traditionally
reserved for System 2 cognitive competencies. Despite their perceived
versatility, the research community is still unraveling effective strategies to
harness these models in such complex domains. The recent discourse introduced
by the paper on LLM Modulo marks a significant stride, proposing a conceptual
framework that enhances the integration of LLMs into diverse planning and
reasoning activities. This workshop paper delves into the practical application
of this framework within the domain of travel planning, presenting a specific
instance of its implementation. We are using the Travel Planning benchmark by
the OSU NLP group, a benchmark for evaluating the performance of LLMs in
producing valid itineraries based on user queries presented in natural
language. While popular methods of enhancing the reasoning abilities of LLMs
such as Chain of Thought, ReAct, and Reflexion achieve a meager 0%, 0.6%, and
0% with GPT3.5-Turbo respectively, our operationalization of the LLM-Modulo
framework for TravelPlanning domain provides a remarkable improvement,
enhancing baseline performances by 4.6x for GPT4-Turbo and even more for older
models like GPT3.5-Turbo from 0% to 5%. Furthermore, we highlight the other
useful roles of LLMs in the planning pipeline, as suggested in LLM-Modulo,
which can be reliably operationalized such as extraction of useful critics and
reformulator for critics.
","['Atharva Gundawar', 'Mudit Verma', 'Lin Guan', 'Karthik Valmeekam', 'Siddhant Bhambri', 'Subbarao Kambhampati']",2024-05-31T05:23:35Z,6
http://arxiv.org/abs/2405.20624v1,Leveraging Large Language Models for Entity Matching,"  Entity matching (EM) is a critical task in data integration, aiming to
identify records across different datasets that refer to the same real-world
entities. Traditional methods often rely on manually engineered features and
rule-based systems, which struggle with diverse and unstructured data. The
emergence of Large Language Models (LLMs) such as GPT-4 offers transformative
potential for EM, leveraging their advanced semantic understanding and
contextual capabilities. This vision paper explores the application of LLMs to
EM, discussing their advantages, challenges, and future research directions.
Additionally, we review related work on applying weak supervision and
unsupervised approaches to EM, highlighting how LLMs can enhance these methods.
","['Qianyu Huang', 'Tongfang Zhao']",2024-05-31T05:22:07Z,2
http://arxiv.org/abs/2405.20612v1,"UniBias: Unveiling and Mitigating LLM Bias through Internal Attention
  and FFN Manipulation","  Large language models (LLMs) have demonstrated impressive capabilities in
various tasks using the in-context learning (ICL) paradigm. However, their
effectiveness is often compromised by inherent bias, leading to prompt
brittleness, i.e., sensitivity to design settings such as example selection,
order, and prompt formatting. Previous studies have addressed LLM bias through
external adjustment of model outputs, but the internal mechanisms that lead to
such bias remain unexplored. Our work delves into these mechanisms,
particularly investigating how feedforward neural networks (FFNs) and attention
heads result in the bias of LLMs. By Interpreting the contribution of
individual FFN vectors and attention heads, we identify the biased LLM
components that skew LLMs' prediction toward specific labels. To mitigate these
biases, we introduce UniBias, an inference-only method that effectively
identifies and eliminates biased FFN vectors and attention heads. Extensive
experiments across 12 NLP datasets demonstrate that UniBias significantly
enhances ICL performance and alleviates prompt brittleness of LLMs.
","['Hanzhang Zhou', 'Zijian Feng', 'Zixiao Zhu', 'Junlang Qian', 'Kezhi Mao']",2024-05-31T03:59:15Z,5
http://arxiv.org/abs/2405.20606v1,"Vision-Language Meets the Skeleton: Progressively Distillation with
  Cross-Modal Knowledge for 3D Action Representation Learning","  Supervised and self-supervised learning are two main training paradigms for
skeleton-based human action recognition. However, the former one-hot
classification requires labor-intensive predefined action categories
annotations, while the latter involves skeleton transformations (e.g.,
cropping) in the pretext tasks that may impair the skeleton structure. To
address these challenges, we introduce a novel skeleton-based training
framework (C$^2$VL) based on Cross-modal Contrastive learning that uses the
progressive distillation to learn task-agnostic human skeleton action
representation from the Vision-Language knowledge prompts. Specifically, we
establish the vision-language action concept space through vision-language
knowledge prompts generated by pre-trained large multimodal models (LMMs),
which enrich the fine-grained details that the skeleton action space lacks.
Moreover, we propose the intra-modal self-similarity and inter-modal
cross-consistency softened targets in the cross-modal contrastive process to
progressively control and guide the degree of pulling vision-language knowledge
prompts and corresponding skeletons closer. These soft instance discrimination
and self-knowledge distillation strategies contribute to the learning of better
skeleton-based action representations from the noisy skeleton-vision-language
pairs. During the inference phase, our method requires only the skeleton data
as the input for action recognition and no longer for vision-language prompts.
Extensive experiments show that our method achieves state-of-the-art results on
NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets. The code will be available
in the future.
","['Yang Chen', 'Tian He', 'Junfeng Fu', 'Ling Wang', 'Jingcai Guo', 'Hong Cheng']",2024-05-31T03:40:15Z,6
http://arxiv.org/abs/2405.20605v1,Searching for internal symbols underlying deep learning,"  Deep learning (DL) enables deep neural networks (DNNs) to automatically learn
complex tasks or rules from given examples without instructions or guiding
principles. As we do not engineer DNNs' functions, it is extremely difficult to
diagnose their decisions, and multiple lines of studies proposed to explain
principles of DNNs/DL operations. Notably, one line of studies suggests that
DNNs may learn concepts, the high level features recognizable to humans. Thus,
we hypothesized that DNNs develop abstract codes, not necessarily recognizable
to humans, which can be used to augment DNNs' decision-making. To address this
hypothesis, we combined foundation segmentation models and unsupervised
learning to extract internal codes and identify potential use of abstract codes
to make DL's decision-making more reliable and safer.
","['Jung H. Lee', 'Sujith Vijayan']",2024-05-31T03:39:26Z,2
http://arxiv.org/abs/2405.20600v1,"Multi-label Class Incremental Emotion Decoding with Augmented Emotional
  Semantics Learning","  Emotion decoding plays an important role in affective human-computer
interaction. However, previous studies ignored the dynamic real-world scenario,
where human experience a blend of multiple emotions which are incrementally
integrated into the model, leading to the multi-label class incremental
learning (MLCIL) problem. Existing methods have difficulty in solving MLCIL
issue due to notorious catastrophic forgetting caused by partial label problem
and inadequate label semantics mining. In this paper, we propose an augmented
emotional semantics learning framework for multi-label class incremental
emotion decoding. Specifically, we design an augmented emotional relation graph
module with label disambiguation to handle the past-missing partial label
problem. Then, we leverage domain knowledge from affective dimension space to
alleviate future-missing partial label problem by knowledge distillation.
Besides, an emotional semantics learning module is constructed with a graph
autoencoder to obtain emotion embeddings in order to guide the
semantic-specific feature decoupling for better multi-label learning. Extensive
experiments on three datasets show the superiority of our method for improving
emotion decoding performance and mitigating forgetting on MLCIL problem.
","['Kaicheng Fu', 'Changde Du', 'Xiaoyu Chen', 'Jie Peng', 'Huiguang He']",2024-05-31T03:16:54Z,5
http://arxiv.org/abs/2405.20594v1,Deep Learning without Weight Symmetry,"  Backpropagation (BP), a foundational algorithm for training artificial neural
networks, predominates in contemporary deep learning. Although highly
successful, it is often considered biologically implausible. A significant
limitation arises from the need for precise symmetry between connections in the
backward and forward pathways to backpropagate gradient signals accurately,
which is not observed in biological brains. Researchers have proposed several
algorithms to alleviate this symmetry constraint, such as feedback alignment
and direct feedback alignment. However, their divergence from backpropagation
dynamics presents challenges, particularly in deeper networks and convolutional
layers. Here we introduce the Product Feedback Alignment (PFA) algorithm. Our
findings demonstrate that PFA closely approximates BP and achieves comparable
performance in deep convolutional networks while avoiding explicit weight
symmetry. Our results offer a novel solution to the longstanding weight
symmetry problem, leading to more biologically plausible learning in deep
convolutional networks compared to earlier methods.
","['Li Ji-An', 'Marcus K. Benna']",2024-05-31T03:11:19Z,2
http://arxiv.org/abs/2405.20585v1,"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large
  Language Models","  In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.
","['Mohammed-Khalil Ghali', 'Abdelrahman Farrag', 'Hajar Sakai', 'Hicham El Baz', 'Yu Jin', 'Sarah Lam']",2024-05-31T02:53:22Z,6
http://arxiv.org/abs/2405.20584v1,"Disrupting Diffusion: Token-Level Attention Erasure Attack against
  Diffusion-based Customization","  With the development of diffusion-based customization methods like
DreamBooth, individuals now have access to train the models that can generate
their personalized images. Despite the convenience, malicious users have
misused these techniques to create fake images, thereby triggering a privacy
security crisis. In light of this, proactive adversarial attacks are proposed
to protect users against customization. The adversarial examples are trained to
distort the customization model's outputs and thus block the misuse. In this
paper, we propose DisDiff (Disrupting Diffusion), a novel adversarial attack
method to disrupt the diffusion model outputs. We first delve into the
intrinsic image-text relationships, well-known as cross-attention, and
empirically find that the subject-identifier token plays an important role in
guiding image generation. Thus, we propose the Cross-Attention Erasure module
to explicitly ""erase"" the indicated attention maps and disrupt the text
guidance. Besides,we analyze the influence of the sampling process of the
diffusion model on Projected Gradient Descent (PGD) attack and introduce a
novel Merit Sampling Scheduler to adaptively modulate the perturbation updating
amplitude in a step-aware manner. Our DisDiff outperforms the state-of-the-art
methods by 12.75% of FDFR scores and 7.25% of ISM scores across two facial
benchmarks and two commonly used prompts on average.
","['Yisu Liu', 'Jinyang An', 'Wanqian Zhang', 'Dayan Wu', 'Jingzi Gu', 'Zheng Lin', 'Weiping Wang']",2024-05-31T02:45:31Z,7
http://arxiv.org/abs/2405.20582v1,"The Point of View of a Sentiment: Towards Clinician Bias Detection in
  Psychiatric Notes","  In psychiatry, negative patient descriptions and stigmatizing language can
contribute to healthcare disparities in two ways: (1) read by patients they can
harm their trust and engagement with the medical center; (2) read by future
providers they may negatively influence the future perspective of a patient. By
leveraging large language models, this work aims to identify the sentiment
expressed in psychiatric clinical notes based on the reader's point of view.
Extracting sentences from the Mount Sinai Health System's large and diverse
clinical notes, we used prompts and in-context learning to adapt three large
language models (GPT-3.5, Llama 2, Mistral) to classify the sentiment conveyed
by the sentences according to the provider or non-provider point of view.
Results showed that GPT-3.5 aligns best to provider point of view, whereas
Mistral aligns best to non-provider point of view.
","['Alissa A. Valentine', 'Lauren A. Lepow', 'Alexander W. Charney', 'Isotta Landi']",2024-05-31T02:28:41Z,4
http://arxiv.org/abs/2405.20574v1,"Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with
  Ko-H5 Benchmark","  This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as
vital tools for evaluating Large Language Models (LLMs) in Korean.
Incorporating private test sets while mirroring the English Open LLM
Leaderboard, we establish a robust evaluation framework that has been well
integrated in the Korean LLM community. We perform data leakage analysis that
shows the benefit of private test sets along with a correlation study within
the Ko-H5 benchmark and temporal analyses of the Ko-H5 score. Moreover, we
present empirical support for the need to expand beyond set benchmarks. We hope
the Open Ko-LLM Leaderboard sets precedent for expanding LLM evaluation to
foster more linguistic diversity.
","['Chanjun Park', 'Hyeonwoo Kim', 'Dahyun Kim', 'Seonghwan Cho', 'Sanghoon Kim', 'Sukyung Lee', 'Yungi Kim', 'Hwalsuk Lee']",2024-05-31T02:05:45Z,8
http://arxiv.org/abs/2405.20583v1,The Gestalt Computational Model,"  Widely employed in cognitive psychology, Gestalt theory elucidates basic
principles in visual perception, but meanwhile presents significant challenges
for computation. The advancement of artificial intelligence requires the
emulation of human cognitive behavior, for which Gestalt theory serves as a
fundamental framework describing human visual cognitive behavior. In this
paper, we utilize persistent homology, a mathematical tool in computational
topology, to develop a computational model for Gestalt theory, addressing the
challenges of quantification and computation. The Gestalt computational model
not only holds promise for applications in artificial intelligence and computer
vision, but also opens a new research direction of computational visual
perception.
","['Yu Chen', 'Hongwei Lin', 'Jiacong Yan']",2024-05-31T02:31:28Z,3
http://arxiv.org/abs/2405.21075v1,"Video-MME: The First-Ever Comprehensive Evaluation Benchmark of
  Multi-modal LLMs in Video Analysis","  In the quest for artificial general intelligence, Multi-modal Large Language
Models (MLLMs) have emerged as a focal point in recent advancements. However,
the predominant focus remains on developing their capabilities in static image
understanding. The potential of MLLMs in processing sequential visual data is
still insufficiently explored, highlighting the absence of a comprehensive,
high-quality assessment of their performance. In this paper, we introduce
Video-MME, the first-ever full-spectrum, Multi-Modal Evaluation benchmark of
MLLMs in Video analysis. Our work distinguishes from existing benchmarks
through four key features: 1) Diversity in video types, spanning 6 primary
visual domains with 30 subfields to ensure broad scenario generalizability; 2)
Duration in temporal dimension, encompassing both short-, medium-, and
long-term videos, ranging from 11 seconds to 1 hour, for robust contextual
dynamics; 3) Breadth in data modalities, integrating multi-modal inputs besides
video frames, including subtitles and audios, to unveil the all-round
capabilities of MLLMs; 4) Quality in annotations, utilizing rigorous manual
labeling by expert annotators to facilitate precise and reliable model
assessment. 900 videos with a total of 256 hours are manually selected and
annotated by repeatedly viewing all the video content, resulting in 2,700
question-answer pairs. With Video-MME, we extensively evaluate various
state-of-the-art MLLMs, including GPT-4 series and Gemini 1.5 Pro, as well as
open-source image models like InternVL-Chat-V1.5 and video models like
LLaVA-NeXT-Video. Our experiments reveal that Gemini 1.5 Pro is the
best-performing commercial model, significantly outperforming the open-source
models. Our dataset along with these findings underscores the need for further
improvements in handling longer sequences and multi-modal data. Project Page:
https://video-mme.github.io
","['Chaoyou Fu', 'Yuhan Dai', 'Yondong Luo', 'Lei Li', 'Shuhuai Ren', 'Renrui Zhang', 'Zihan Wang', 'Chenyu Zhou', 'Yunhang Shen', 'Mengdan Zhang', 'Peixian Chen', 'Yanwei Li', 'Shaohui Lin', 'Sirui Zhao', 'Ke Li', 'Tong Xu', 'Xiawu Zheng', 'Enhong Chen', 'Rongrong Ji', 'Xing Sun']",2024-05-31T17:59:47Z,20
http://arxiv.org/abs/2405.21070v1,"Generalization Beyond Data Imbalance: A Controlled Study on CLIP for
  Transferable Insights","  Severe data imbalance naturally exists among web-scale vision-language
datasets. Despite this, we find CLIP pre-trained thereupon exhibits notable
robustness to the data imbalance compared to supervised learning, and
demonstrates significant effectiveness in learning generalizable
representations. With an aim to investigate the reasons behind this finding, we
conduct controlled experiments to study various underlying factors, and reveal
that CLIP's pretext task forms a dynamic classification problem wherein only a
subset of classes is present in training. This isolates the bias from dominant
classes and implicitly balances the learning signal. Furthermore, the
robustness and discriminability of CLIP improve with more descriptive language
supervision, larger data scale, and broader open-world concepts, which are
inaccessible to supervised learning. Our study not only uncovers the mechanisms
behind CLIP's generalizability beyond data imbalance but also provides
transferable insights for the research community. The findings are validated in
both supervised and self-supervised learning, enabling models trained on
imbalanced data to achieve CLIP-level performance on diverse recognition tasks.
Code will be available at: https://github.com/CVMI-Lab/clip-beyond-tail.
","['Xin Wen', 'Bingchen Zhao', 'Yilun Chen', 'Jiangmiao Pang', 'Xiaojuan Qi']",2024-05-31T17:57:24Z,5
http://arxiv.org/abs/2405.21022v1,"You Only Scan Once: Efficient Multi-dimension Sequential Modeling with
  LightNet","  Linear attention mechanisms have gained prominence in causal language models
due to their linear computational complexity and enhanced speed. However, the
inherent decay mechanism in linear attention presents challenges when applied
to multi-dimensional sequence modeling tasks, such as image processing and
multi-modal learning. In these scenarios, the utilization of sequential
scanning to establish a global receptive field necessitates multiple scans for
multi-dimensional data, thereby leading to inefficiencies. This paper
identifies the inefficiency caused by a multiplicative linear recurrence and
proposes an efficient alternative additive linear recurrence to avoid the
issue, as it can handle multi-dimensional data within a single scan. We further
develop an efficient multi-dimensional sequential modeling framework called
LightNet based on the new recurrence. Moreover, we present two new
multi-dimensional linear relative positional encoding methods, MD-TPE and
MD-LRPE to enhance the model's ability to discern positional information in
multi-dimensional scenarios. Our empirical evaluations across various tasks,
including image classification, image generation, bidirectional language
modeling, and autoregressive language modeling, demonstrate the efficacy of
LightNet, showcasing its potential as a versatile and efficient solution for
multi-dimensional sequential modeling.
","['Zhen Qin', 'Yuxin Mao', 'Xuyang Shen', 'Dong Li', 'Jing Zhang', 'Yuchao Dai', 'Yiran Zhong']",2024-05-31T17:09:16Z,7
http://arxiv.org/abs/2405.20994v1,"CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to
  Web Relevance Ranking","  We present CWRCzech, Click Web Ranking dataset for Czech, a 100M
query-document Czech click dataset for relevance ranking with user behavior
data collected from search engine logs of Seznam.cz. To the best of our
knowledge, CWRCzech is the largest click dataset with raw text published so
far. It provides document positions in the search results as well as
information about user behavior: 27.6M clicked documents and 10.8M dwell times.
In addition, we also publish a manually annotated Czech test for the relevance
task, containing nearly 50k query-document pairs, each annotated by at least 2
annotators. Finally, we analyze how the user behavior data improve relevance
ranking and show that models trained on data automatically harnessed at
sufficient scale can surpass the performance of models trained on human
annotated data. CWRCzech is published under an academic non-commercial license
and is available to the research community at
https://github.com/seznam/CWRCzech.
","['Josef Vonášek', 'Milan Straka', 'Rostislav Krč', 'Lenka Lasoňová', 'Ekaterina Egorova', 'Jana Straková', 'Jakub Náplava']",2024-05-31T16:38:54Z,7
http://arxiv.org/abs/2405.20973v1,LCQ: Low-Rank Codebook based Quantization for Large Language Models,"  Large language models~(LLMs) have recently demonstrated promising performance
in many tasks. However, the high storage and computational cost of LLMs has
become a challenge for deploying LLMs. Weight quantization has been widely used
for model compression, which can reduce both storage and computational cost.
Most existing weight quantization methods for LLMs use a rank-one codebook for
quantization, which results in substantial accuracy loss when the compression
ratio is high. In this paper, we propose a novel weight quantization method,
called low-rank codebook based quantization~(LCQ), for LLMs. LCQ adopts a
low-rank codebook, the rank of which can be larger than one, for quantization.
Experiments show that LCQ can achieve better accuracy than existing methods
with a negligibly extra storage cost.
","['Wen-Pu Cai', 'Wu-Jun Li']",2024-05-31T16:21:05Z,2
http://arxiv.org/abs/2405.20967v1,"Superlatives in Context: Explicit and Implicit Domain Restrictions for
  Superlative Frames","  Superlatives are used to single out elements with a maximal/minimal property.
Semantically, superlatives perform a set comparison: something (or some things)
has the min/max property out of a set. As such, superlatives provide an ideal
phenomenon for studying implicit phenomena and discourse restrictions. While
this comparison set is often not explicitly defined, its (implicit)
restrictions can be inferred from the discourse context the expression appears
in. In this work we provide an extensive computational study on the semantics
of superlatives. We propose a unified account of superlative semantics which
allows us to derive a broad-coverage annotation schema. Using this unified
schema we annotated a multi-domain dataset of superlatives and their semantic
interpretations. We specifically focus on interpreting implicit or ambiguous
superlative expressions, by analyzing how the discourse context restricts the
set of interpretations. In a set of experiments we then analyze how well models
perform at variations of predicting superlative semantics, with and without
context. We show that the fine-grained semantics of superlatives in context can
be challenging for contemporary models, including GPT-4.
","['Valentina Pyatkin', 'Bonnie Webber', 'Ido Dagan', 'Reut Tsarfaty']",2024-05-31T16:14:06Z,4
http://arxiv.org/abs/2405.20900v1,"Large Language Models: A New Approach for Privacy Policy Analysis at
  Scale","  The number and dynamic nature of web and mobile applications presents
significant challenges for assessing their compliance with data protection
laws. In this context, symbolic and statistical Natural Language Processing
(NLP) techniques have been employed for the automated analysis of these
systems' privacy policies. However, these techniques typically require
labor-intensive and potentially error-prone manually annotated datasets for
training and validation. This research proposes the application of Large
Language Models (LLMs) as an alternative for effectively and efficiently
extracting privacy practices from privacy policies at scale. Particularly, we
leverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the
optimal design of prompts, parameters, and models, incorporating advanced
strategies such as few-shot learning. We further illustrate its capability to
detect detailed and varied privacy practices accurately. Using several renowned
datasets in the domain as a benchmark, our evaluation validates its exceptional
performance, achieving an F1 score exceeding 93%. Besides, it does so with
reduced costs, faster processing times, and fewer technical knowledge
requirements. Consequently, we advocate for LLM-based solutions as a sound
alternative to traditional NLP techniques for the automated analysis of privacy
policies at scale.
","['David Rodriguez', 'Ian Yang', 'Jose M. Del Alamo', 'Norman Sadeh']",2024-05-31T15:12:33Z,4
http://arxiv.org/abs/2405.20895v1,"A comparison of correspondence analysis with PMI-based word embedding
  methods","  Popular word embedding methods such as GloVe and Word2Vec are related to the
factorization of the pointwise mutual information (PMI) matrix. In this paper,
we link correspondence analysis (CA) to the factorization of the PMI matrix. CA
is a dimensionality reduction method that uses singular value decomposition
(SVD), and we show that CA is mathematically close to the weighted
factorization of the PMI matrix. In addition, we present variants of CA that
turn out to be successful in the factorization of the word-context matrix, i.e.
CA applied to a matrix where the entries undergo a square-root transformation
(ROOT-CA) and a root-root transformation (ROOTROOT-CA). An empirical comparison
among CA- and PMI-based methods shows that overall results of ROOT-CA and
ROOTROOT-CA are slightly better than those of the PMI-based methods.
","['Qianqian Qi', 'David J. Hessen', 'Peter G. M. van der Heijden']",2024-05-31T15:04:15Z,3
http://arxiv.org/abs/2405.20852v1,"Towards Spoken Language Understanding via Multi-level Multi-grained
  Contrastive Learning","  Spoken language understanding (SLU) is a core task in task-oriented dialogue
systems, which aims at understanding the user's current goal through
constructing semantic frames. SLU usually consists of two subtasks, including
intent detection and slot filling. Although there are some SLU frameworks joint
modeling the two subtasks and achieving high performance, most of them still
overlook the inherent relationships between intents and slots and fail to
achieve mutual guidance between the two subtasks. To solve the problem, we
propose a multi-level multi-grained SLU framework MMCL to apply contrastive
learning at three levels, including utterance level, slot level, and word level
to enable intent and slot to mutually guide each other. For the utterance
level, our framework implements coarse granularity contrastive learning and
fine granularity contrastive learning simultaneously. Besides, we also apply
the self-distillation method to improve the robustness of the model.
Experimental results and further analysis demonstrate that our proposed model
achieves new state-of-the-art results on two public multi-intent SLU datasets,
obtaining a 2.6 overall accuracy improvement on the MixATIS dataset compared to
previous best models.
","['Xuxin Cheng', 'Wanshi Xu', 'Zhihong Zhu', 'Hongxiang Li', 'Yuexian Zou']",2024-05-31T14:34:23Z,5
http://arxiv.org/abs/2405.20850v1,Improving Reward Models with Synthetic Critiques,"  Reward models (RM) play a critical role in aligning language models through
the process of reinforcement learning from human feedback. RMs are trained to
predict a score reflecting human preference, which requires significant time
and cost for human annotation. Additionally, RMs tend to quickly overfit on
superficial features in the training set, hindering their generalization
performance on unseen distributions. We propose a novel approach using
synthetic natural language critiques generated by large language models to
provide additional feedback, evaluating aspects such as instruction following,
correctness, and style. This offers richer signals and more robust features for
RMs to assess and score on. We demonstrate that high-quality critiques improve
the performance and data efficiency of RMs initialized from different
pretrained models. Conversely, we also show that low-quality critiques
negatively impact performance. Furthermore, incorporating critiques enhances
the interpretability and robustness of RM training.
","['Zihuiwen Ye', 'Fraser Greenlee-Scott', 'Max Bartolo', 'Phil Blunsom', 'Jon Ander Campos', 'Matthias Gallé']",2024-05-31T14:33:07Z,6
http://arxiv.org/abs/2405.20833v1,"That's Optional: A Contemporary Exploration of ""that"" Omission in
  English Subordinate Clauses","  The Uniform Information Density (UID) hypothesis posits that speakers
optimize the communicative properties of their utterances by avoiding spikes in
information, thereby maintaining a relatively uniform information profile over
time. This paper investigates the impact of UID principles on syntactic
reduction, specifically focusing on the optional omission of the connector
""that"" in English subordinate clauses. Building upon previous research, we
extend our investigation to a larger corpus of written English, utilize
contemporary large language models (LLMs) and extend the information-uniformity
principles by the notion of entropy, to estimate the UID manifestations in the
usecase of syntactic reduction choices.
",['Ella Rabinovich'],2024-05-31T14:23:30Z,1
http://arxiv.org/abs/2405.20830v1,"Self-Augmented Preference Optimization: Off-Policy Paradigms for
  Language Model Alignment","  Traditional language model alignment methods, such as Direct Preference
Optimization (DPO), are limited by their dependence on static, pre-collected
paired preference data, which hampers their adaptability and practical
applicability. To overcome this limitation, we introduce Self-Augmented
Preference Optimization (SAPO), an effective and scalable training paradigm
that does not require existing paired data. Building on the self-play concept,
which autonomously generates negative responses, we further incorporate an
off-policy learning pipeline to enhance data exploration and exploitation.
Specifically, we employ an Exponential Moving Average (EMA) model in
conjunction with a replay buffer to enable dynamic updates of response
segments, effectively integrating real-time feedback with insights from
historical data. Our comprehensive evaluations of the LLaMA3-8B and Mistral-7B
models across benchmarks, including the Open LLM Leaderboard, IFEval,
AlpacaEval 2.0, and MT-Bench, demonstrate that SAPO matches or surpasses
established offline contrastive baselines, such as DPO and Odds Ratio
Preference Optimization, and outperforms offline self-play methods like SPIN.
Our code is available at https://github.com/yinyueqin/SAPO
","['Yueqin Yin', 'Zhendong Wang', 'Yujia Xie', 'Weizhu Chen', 'Mingyuan Zhou']",2024-05-31T14:21:04Z,5
http://arxiv.org/abs/2405.20818v1,"An iterated learning model of language change that mixes supervised and
  unsupervised learning","  The iterated learning model is an agent-based model of language change in
which language is transmitted from a tutor to a pupil which itself becomes a
tutor to a new pupil, and so on. Languages that are stable, expressive, and
compositional arise spontaneously as a consequence of a language transmission
bottleneck. Previous models have implemented an agent's mapping from signals to
meanings using an artificial neural network decoder, but have relied on an
unrealistic and computationally expensive process of obversion to implement the
associated encoder, mapping from meanings to signals. Here, a new model is
presented in which both decoder and encoder are neural networks, trained
separately through supervised learning, and trained together through
unsupervised learning in the form of an autoencoder. This avoids the
substantial computational burden entailed in obversion and introduces a mixture
of supervised and unsupervised learning as observed during human development.
","['Jack Bunyan', 'Seth Bullock', 'Conor Houghton']",2024-05-31T14:14:01Z,3
http://arxiv.org/abs/2405.20755v1,"Improving code-mixed hate detection by native sample mixing: A case
  study for Hindi-English code-mixed scenario","  Hate detection has long been a challenging task for the NLP community. The
task becomes complex in a code-mixed environment because the models must
understand the context and the hate expressed through language alteration.
Compared to the monolingual setup, we see very less work on code-mixed hate as
large-scale annotated hate corpora are unavailable to make the study. To
overcome this bottleneck, we propose using native language hate samples. We
hypothesise that in the era of multilingual language models (MLMs), hate in
code-mixed settings can be detected by majorly relying on the native language
samples. Even though the NLP literature reports the effectiveness of MLMs on
hate detection in many cross-lingual settings, their extensive evaluation in a
code-mixed scenario is yet to be done. This paper attempts to fill this gap
through rigorous empirical experiments. We considered the Hindi-English
code-mixed setup as a case study as we have the linguistic expertise for the
same. Some of the interesting observations we got are: (i) adding native hate
samples in the code-mixed training set, even in small quantity, improved the
performance of MLMs for code-mixed hate detection, (ii) MLMs trained with
native samples alone observed to be detecting code-mixed hate to a large
extent, (iii) The visualisation of attention scores revealed that, when native
samples were included in training, MLMs could better focus on the hate emitting
words in the code-mixed context, and (iv) finally, when hate is subjective or
sarcastic, naively mixing native samples doesn't help much to detect code-mixed
hate. We will release the data and code repository to reproduce the reported
results.
","['Debajyoti Mazumder', 'Aakash Kumar', 'Jasabanta Patro']",2024-05-31T11:43:31Z,3
http://arxiv.org/abs/2405.20703v1,"It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment
  Analysis Performance","  Aspect-Based Sentiment Analysis (ABSA) involves extracting opinions from
textual data about specific entities and their corresponding aspects through
various complementary subtasks. Several prior research has focused on
developing ad hoc designs of varying complexities for these subtasks. In this
paper, we present a generative framework extensible to any ABSA subtask. We
build upon the instruction tuned model proposed by Scaria et al. (2023), who
present an instruction-based model with task descriptions followed by
in-context examples on ABSA subtasks. We propose PFInstruct, an extension to
this instruction learning paradigm by appending an NLP-related task prefix to
the task description. This simple approach leads to improved performance across
all tested SemEval subtasks, surpassing previous state-of-the-art (SOTA) on the
ATE subtask (Rest14) by +3.28 F1-score, and on the AOOE subtask by an average
of +5.43 F1-score across SemEval datasets. Furthermore, we explore the impact
of the prefix-enhanced prompt quality on the ABSA subtasks and find that even a
noisy prefix enhances model performance compared to the baseline. Our method
also achieves competitive results on a biomedical domain dataset (ERSA).
","['Laura Cabello', 'Uchenna Akujuobi']",2024-05-31T08:57:09Z,2
http://arxiv.org/abs/2405.20684v1,Joint Embeddings for Graph Instruction Tuning,"  Large Language Models (LLMs) have achieved impressive performance in text
understanding and have become an essential tool for building smart assistants.
Originally focusing on text, they have been enhanced with multimodal
capabilities in recent works that successfully built visual instruction
following assistants. As far as the graph modality goes, however, no such
assistants have yet been developed. Graph structures are complex in that they
represent relation between different features and are permutation invariant.
Moreover, representing them in purely textual form does not always lead to good
LLM performance even for finetuned models. As a result, there is a need to
develop a new method to integrate graphs in LLMs for general graph
understanding. This work explores the integration of the graph modality in LLM
for general graph instruction following tasks. It aims at producing a deep
learning model that enhances an underlying LLM with graph embeddings and trains
it to understand them and to produce, given an instruction, an answer grounded
in the graph representation. The approach performs significantly better than a
graph to text approach and remains consistent even for larger graphs.
","['Vlad Argatu', 'Aaron Haag', 'Oliver Lohse']",2024-05-31T08:26:47Z,3
http://arxiv.org/abs/2405.20657v1,DORY: Deliberative Prompt Recovery for LLM,"  Prompt recovery in large language models (LLMs) is crucial for understanding
how LLMs work and addressing concerns regarding privacy, copyright, etc. The
trend towards inference-only APIs complicates this task by restricting access
to essential outputs for recovery. To tackle this challenge, we extract
prompt-related information from limited outputs and identify a strong(negative)
correlation between output probability-based uncertainty and the success of
prompt recovery. This finding led to the development of Deliberative PrOmpt
RecoverY (DORY), our novel approach that leverages uncertainty to recover
prompts accurately. DORY involves reconstructing drafts from outputs, refining
these with hints, and filtering out noise based on uncertainty. Our evaluation
across diverse LLMs and prompt benchmarks shows that DORY outperforms existing
baselines, improving performance by approximately 10.82% and establishing a new
state-of-the-art record in prompt recovery tasks. Significantly, DORY operates
using a single LLM without any external resources or model, offering a
cost-effective, user-friendly prompt recovery solution.
","['Lirong Gao', 'Ru Peng', 'Yiming Zhang', 'Junbo Zhao']",2024-05-31T07:51:16Z,4
http://arxiv.org/abs/2405.20654v1,"Passage-specific Prompt Tuning for Passage Reranking in Question
  Answering with Large Language Models","  Effective passage retrieval and reranking methods have been widely utilized
to identify suitable candidates in open-domain question answering tasks, recent
studies have resorted to LLMs for reranking the retrieved passages by the
log-likelihood of the question conditioned on each passage. Although these
methods have demonstrated promising results, the performance is notably
sensitive to the human-written prompt (or hard prompt), and fine-tuning LLMs
can be computationally intensive and time-consuming. Furthermore, this approach
limits the leverage of question-passage relevance pairs and passage-specific
knowledge to enhance the ranking capabilities of LLMs. In this paper, we
propose passage-specific prompt tuning for reranking in open-domain question
answering (PSPT): a parameter-efficient method that fine-tunes learnable
passage-specific soft prompts, incorporating passage-specific knowledge from a
limited set of question-passage relevance pairs. The method involves ranking
retrieved passages based on the log-likelihood of the model generating the
question conditioned on each passage and the learned soft prompt. We conducted
extensive experiments utilizing the Llama-2-chat-7B model across three publicly
available open-domain question answering datasets and the results demonstrate
the effectiveness of the proposed approach.
","['Xuyang Wu', 'Zhiyuan Peng', 'Sravanthi Rajanala', 'Hsin-Tai Wu', 'Yi Fang']",2024-05-31T07:43:42Z,5
http://arxiv.org/abs/2405.20649v1,Reward-based Input Construction for Cross-document Relation Extraction,"  Relation extraction (RE) is a fundamental task in natural language
processing, aiming to identify relations between target entities in text. While
many RE methods are designed for a single sentence or document, cross-document
RE has emerged to address relations across multiple long documents. Given the
nature of long documents in cross-document RE, extracting document embeddings
is challenging due to the length constraints of pre-trained language models.
Therefore, we propose REward-based Input Construction (REIC), the first
learning-based sentence selector for cross-document RE. REIC extracts sentences
based on relational evidence, enabling the RE module to effectively infer
relations. Since supervision of evidence sentences is generally unavailable, we
train REIC using reinforcement learning with RE prediction scores as rewards.
Experimental results demonstrate the superiority of our method over heuristic
methods for different RE structures and backbones in cross-document RE. Our
code is publicly available at https://github.com/aailabkaist/REIC.
","['Byeonghu Na', 'Suhyeon Jo', 'Yeongmin Kim', 'Il-Chul Moon']",2024-05-31T07:30:34Z,4
http://arxiv.org/abs/2405.20648v1,"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision
  Models For Video Captioning and Summarization","  Video is an increasingly prominent and information-dense medium, yet it poses
substantial challenges for language models. A typical video consists of a
sequence of shorter segments, or shots, that collectively form a coherent
narrative. Each shot is analogous to a word in a sentence where multiple data
streams of information (such as visual and auditory data) must be processed
simultaneously. Comprehension of the entire video requires not only
understanding the visual-audio information of each shot but also requires that
the model links the ideas between each shot to generate a larger,
all-encompassing story. Despite significant progress in the field, current
works often overlook videos' more granular shot-by-shot semantic information.
In this project, we propose a family of efficient large language vision models
(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By
leveraging better pretraining and data collection strategies, we extend the
abilities of existing small LLVMs from being able to understand a picture to
being able to understand a sequence of frames. Specifically, we show that
Shotluck Holmes achieves better performance than state-of-the-art results on
the Shot2Story video captioning and summary task with significantly smaller and
more computationally efficient models.
","['Richard Luo', 'Austin Peng', 'Adithya Vasudev', 'Rishabh Jain']",2024-05-31T07:30:24Z,4
http://arxiv.org/abs/2405.20646v1,"Large Language Models Enhanced Sequential Recommendation for Long-tail
  User and Item","  Sequential recommendation systems (SRS) serve the purpose of predicting
users' subsequent preferences based on their past interactions and have been
applied across various domains such as e-commerce and social networking
platforms. However, practical SRS encounters challenges due to the fact that
most users engage with only a limited number of items, while the majority of
items are seldom consumed. These challenges, termed as the long-tail user and
long-tail item dilemmas, often create obstacles for traditional SRS methods.
Mitigating these challenges is crucial as they can significantly impact user
satisfaction and business profitability. While some research endeavors have
alleviated these issues, they still grapple with issues such as seesaw or noise
stemming from the scarcity of interactions. The emergence of large language
models (LLMs) presents a promising avenue to address these challenges from a
semantic standpoint. In this study, we introduce the Large Language Models
Enhancement framework for Sequential Recommendation (LLM-ESR), which leverages
semantic embeddings from LLMs to enhance SRS performance without increasing
computational overhead. To combat the long-tail item challenge, we propose a
dual-view modeling approach that fuses semantic information from LLMs with
collaborative signals from traditional SRS. To address the long-tail user
challenge, we introduce a retrieval augmented self-distillation technique to
refine user preference representations by incorporating richer interaction data
from similar users. Through comprehensive experiments conducted on three
authentic datasets using three widely used SRS models, our proposed enhancement
framework demonstrates superior performance compared to existing methodologies.
","['Qidong Liu', 'Xian Wu', 'Xiangyu Zhao', 'Yejing Wang', 'Zijian Zhang', 'Feng Tian', 'Yefeng Zheng']",2024-05-31T07:24:42Z,7
http://arxiv.org/abs/2405.20613v1,"FineRadScore: A Radiology Report Line-by-Line Evaluation Technique
  Generating Corrections with Severity Scores","  The current gold standard for evaluating generated chest x-ray (CXR) reports
is through radiologist annotations. However, this process can be extremely
time-consuming and costly, especially when evaluating large numbers of reports.
In this work, we present FineRadScore, a Large Language Model (LLM)-based
automated evaluation metric for generated CXR reports. Given a candidate report
and a ground-truth report, FineRadScore gives the minimum number of
line-by-line corrections required to go from the candidate to the ground-truth
report. Additionally, FineRadScore provides an error severity rating with each
correction and generates comments explaining why the correction was needed. We
demonstrate that FineRadScore's corrections and error severity scores align
with radiologist opinions. We also show that, when used to judge the quality of
the report as a whole, FineRadScore aligns with radiologists as well as current
state-of-the-art automated CXR evaluation metrics. Finally, we analyze
FineRadScore's shortcomings to provide suggestions for future improvements.
","['Alyssa Huang', 'Oishi Banerjee', 'Kay Wu', 'Eduardo Pontes Reis', 'Pranav Rajpurkar']",2024-05-31T04:05:09Z,5
http://arxiv.org/abs/2405.20608v1,Identifying while Learning for Document Event Causality Identification,"  Event Causality Identification (ECI) aims to detect whether there exists a
causal relation between two events in a document. Existing studies adopt a kind
of identifying after learning paradigm, where events' representations are first
learned and then used for the identification. Furthermore, they mainly focus on
the causality existence, but ignoring causal direction. In this paper, we take
care of the causal direction and propose a new identifying while learning mode
for the ECI task. We argue that a few causal relations can be easily identified
with high confidence, and the directionality and structure of these identified
causalities can be utilized to update events' representations for boosting next
round of causality identification. To this end, this paper designs an
*iterative learning and identifying framework*: In each iteration, we construct
an event causality graph, on which events' causal structure representations are
updated for boosting causal identification. Experiments on two public datasets
show that our approach outperforms the state-of-the-art algorithms in both
evaluations for causality existence identification and direction
identification.
","['Cheng Liu', 'Wei Xiang', 'Bang Wang']",2024-05-31T03:48:00Z,3
http://arxiv.org/abs/2405.20602v1,"Masked Language Modeling Becomes Conditional Density Estimation for
  Tabular Data Synthesis","  In this paper, our goal is to generate synthetic data for heterogeneous
(mixed-type) tabular datasets with high machine learning utility (MLu). Given
that the MLu performance relies on accurately approximating the conditional
distributions, we focus on devising a synthetic data generation method based on
conditional distribution estimation. We propose a novel synthetic data
generation method, MaCoDE, by redefining the multi-class classification task of
Masked Language Modeling (MLM) as histogram-based non-parametric conditional
density estimation. Our proposed method enables estimating conditional
densities across arbitrary combinations of target and conditional variables.
Furthermore, we demonstrate that our proposed method bridges the theoretical
gap between distributional learning and MLM. To validate the effectiveness of
our proposed model, we conduct synthetic data generation experiments on 10
real-world datasets. Given the analogy between predicting masked input tokens
in MLM and missing data imputation, we also evaluate the performance of
multiple imputations on incomplete datasets with various missing data
mechanisms. Moreover, our proposed model offers the advantage of enabling
adjustments to data privacy levels without requiring re-training.
","['Seunghwan An', 'Gyeongdong Woo', 'Jaesung Lim', 'ChangHyun Kim', 'Sungchul Hong', 'Jong-June Jeon']",2024-05-31T03:26:42Z,6
http://arxiv.org/abs/2405.20588v1,"DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large
  Language Models","  Recently, while large language models (LLMs) have demonstrated impressive
results, they still suffer from hallucination, i.e., the generation of false
information. Model editing is the task of fixing factual mistakes in LLMs; yet,
most previous works treat it as a one-time task, paying little attention to
ever-emerging mistakes generated by LLMs. We address the task of sequential
model editing (SME) that aims to rectify mistakes continuously. A Dynamic
Auxiliary Fusion Network (DAFNet) is designed to enhance the semantic
interaction among the factual knowledge within the entire sequence, preventing
catastrophic forgetting during the editing process of multiple knowledge
triples. Specifically, (1) for semantic fusion within a relation triple, we
aggregate the intra-editing attention flow into auto-regressive self-attention
with token-level granularity in LLMs. We further leverage multi-layer diagonal
inter-editing attention flow to update the weighted representations of the
entire sequence-level granularity. (2) Considering that auxiliary parameters
are required to store the knowledge for sequential editing, we construct a new
dataset named \textbf{DAFSet}, fulfilling recent, popular, long-tail and robust
properties to enhance the generality of sequential editing. Experiments show
DAFNet significantly outperforms strong baselines in single-turn and sequential
editing. The usage of DAFSet also consistently improves the performance of
other auxiliary network-based methods in various scenarios
","['Taolin Zhang', 'Qizhou Chen', 'Dongyang Li', 'Chengyu Wang', 'Xiaofeng He', 'Longtao Huang', 'Hui Xue', 'Jun Huang']",2024-05-31T02:56:49Z,8
http://arxiv.org/abs/2405.20914v1,"RASE: Efficient Privacy-preserving Data Aggregation against Disclosure
  Attacks for IoTs","  The growing popular awareness of personal privacy raises the following
quandary: what is the new paradigm for collecting and protecting the data
produced by ever-increasing sensor devices. Most previous studies on co-design
of data aggregation and privacy preservation assume that a trusted fusion
center adheres to privacy regimes. Very recent work has taken steps towards
relaxing the assumption by allowing data contributors to locally perturb their
own data. Although these solutions withhold some data content to mitigate
privacy risks, they have been shown to offer insufficient protection against
disclosure attacks. Aiming at providing a more rigorous data safeguard for the
Internet of Things (IoTs), this paper initiates the study of privacy-preserving
data aggregation. We propose a novel paradigm (called RASE), which can be
generalized into a 3-step sequential procedure, noise addition, followed by
random permutation, and then parameter estimation. Specially, we design a
differentially private randomizer, which carefully guides data contributors to
obfuscate the truth. Then, a shuffler is employed to receive the noisy data
from all data contributors. After that, it breaks the correct linkage between
senders and receivers by applying a random permutation. The estimation phase
involves using inaccurate data to calculate an approximate aggregate value.
Extensive simulations are provided to explore the privacy-utility landscape of
our RASE.
","['Zuyan Wang', 'Jun Tao', 'Dika Zou']",2024-05-31T15:21:38Z,3
http://arxiv.org/abs/2405.20641v1,"Query Provenance Analysis for Robust and Efficient Query-based Black-box
  Attack Defense","  Query-based black-box attacks have emerged as a significant threat to machine
learning systems, where adversaries can manipulate the input queries to
generate adversarial examples that can cause misclassification of the model. To
counter these attacks, researchers have proposed Stateful Defense Models (SDMs)
for detecting adversarial query sequences and rejecting queries that are
""similar"" to the history queries. Existing state-of-the-art (SOTA) SDMs (e.g.,
BlackLight and PIHA) have shown great effectiveness in defending against these
attacks. However, recent studies have shown that they are vulnerable to
Oracle-guided Adaptive Rejection Sampling (OARS) attacks, which is a stronger
adaptive attack strategy. It can be easily integrated with existing attack
algorithms to evade the SDMs by generating queries with fine-tuned direction
and step size of perturbations utilizing the leaked decision information from
the SDMs.
  In this paper, we propose a novel approach, Query Provenance Analysis (QPA),
for more robust and efficient SDMs. QPA encapsulates the historical
relationships among queries as the sequence feature to capture the fundamental
difference between benign and adversarial query sequences. To utilize the query
provenance, we propose an efficient query provenance analysis algorithm with
dynamic management. We evaluate QPA compared with two baselines, BlackLight and
PIHA, on four widely used datasets with six query-based black-box attack
algorithms. The results show that QPA outperforms the baselines in terms of
defense effectiveness and efficiency on both non-adaptive and adaptive attacks.
Specifically, QPA reduces the Attack Success Rate (ASR) of OARS to 4.08%,
comparing to 77.63% and 87.72% for BlackLight and PIHA, respectively. Moreover,
QPA also achieves 7.67x and 2.25x higher throughput than BlackLight and PIHA.
","['Shaofei Li', 'Ziqi Zhang', 'Haomin Jia', 'Ding Li', 'Yao Guo', 'Xiangqun Chen']",2024-05-31T06:56:54Z,6
http://arxiv.org/abs/2405.21059v1,"Unified Directly Denoising for Both Variance Preserving and Variance
  Exploding Diffusion Models","  Previous work has demonstrated that, in the Variance Preserving (VP)
scenario, the nascent Directly Denoising Diffusion Models (DDDM) can generate
high-quality images in one step while achieving even better performance in
multistep sampling. However, the Pseudo-LPIPS loss used in DDDM leads to
concerns about the bias in assessment. Here, we propose a unified DDDM (uDDDM)
framework that generates images in one-step/multiple steps for both Variance
Preserving (VP) and Variance Exploding (VE) cases. We provide theoretical
proofs of the existence and uniqueness of the model's solution paths, as well
as the non-intersecting property of the sampling paths. Additionally, we
propose an adaptive Pseudo-Huber loss function to balance the convergence to
the true solution and the stability of convergence process.Through a
comprehensive evaluation, we demonstrate that uDDDMs achieve FID scores
comparable to the best-performing methods available for CIFAR-10 in both VP and
VE. Specifically, uDDDM achieves one-step generation on CIFAR10 with FID of
2.63 and 2.53 for VE and VP respectively. By extending the sampling to 1000
steps, we further reduce FID score to 1.71 and 1.65 for VE and VP respectively,
setting state-of-the-art performance in both cases.
","['Jingjing Wang', 'Dan Zhang', 'Feng Luo']",2024-05-31T17:49:51Z,3
http://arxiv.org/abs/2405.21050v1,Spectrum-Aware Parameter Efficient Fine-Tuning for Diffusion Models,"  Adapting large-scale pre-trained generative models in a parameter-efficient
manner is gaining traction. Traditional methods like low rank adaptation
achieve parameter efficiency by imposing constraints but may not be optimal for
tasks requiring high representation capacity. We propose a novel spectrum-aware
adaptation framework for generative models. Our method adjusts both singular
values and their basis vectors of pretrained weights. Using the Kronecker
product and efficient Stiefel optimizers, we achieve parameter-efficient
adaptation of orthogonal matrices. We introduce Spectral Orthogonal
Decomposition Adaptation (SODA), which balances computational efficiency and
representation capacity. Extensive evaluations on text-to-image diffusion
models demonstrate SODA's effectiveness, offering a spectrum-aware alternative
to existing fine-tuning methods.
","['Xinxi Zhang', 'Song Wen', 'Ligong Han', 'Felix Juefei-Xu', 'Akash Srivastava', 'Junzhou Huang', 'Hao Wang', 'Molei Tao', 'Dimitris N. Metaxas']",2024-05-31T17:43:35Z,9
http://arxiv.org/abs/2405.21048v1,"Kaleido Diffusion: Improving Conditional Diffusion Models with
  Autoregressive Latent Modeling","  Diffusion models have emerged as a powerful tool for generating high-quality
images from textual descriptions. Despite their successes, these models often
exhibit limited diversity in the sampled images, particularly when sampling
with a high classifier-free guidance weight. To address this issue, we present
Kaleido, a novel approach that enhances the diversity of samples by
incorporating autoregressive latent priors. Kaleido integrates an
autoregressive language model that encodes the original caption and generates
latent variables, serving as abstract and intermediary representations for
guiding and facilitating the image generation process. In this paper, we
explore a variety of discrete latent representations, including textual
descriptions, detection bounding boxes, object blobs, and visual tokens. These
representations diversify and enrich the input conditions to the diffusion
models, enabling more diverse outputs. Our experimental results demonstrate
that Kaleido effectively broadens the diversity of the generated image samples
from a given textual description while maintaining high image quality.
Furthermore, we show that Kaleido adheres closely to the guidance provided by
the generated latent variables, demonstrating its capability to effectively
control and direct the image generation process.
","['Jiatao Gu', 'Ying Shen', 'Shuangfei Zhai', 'Yizhe Zhang', 'Navdeep Jaitly', 'Joshua M. Susskind']",2024-05-31T17:41:11Z,6
http://arxiv.org/abs/2405.21013v1,"StrucTexTv3: An Efficient Vision-Language Model for Text-rich Image
  Perception, Comprehension, and Beyond","  Text-rich images have significant and extensive value, deeply integrated into
various aspects of human life. Notably, both visual cues and linguistic symbols
in text-rich images play crucial roles in information transmission but are
accompanied by diverse challenges. Therefore, the efficient and effective
understanding of text-rich images is a crucial litmus test for the capability
of Vision-Language Models. We have crafted an efficient vision-language model,
StrucTexTv3, tailored to tackle various intelligent tasks for text-rich images.
The significant design of StrucTexTv3 is presented in the following aspects:
Firstly, we adopt a combination of an effective multi-scale reduced visual
transformer and a multi-granularity token sampler (MG-Sampler) as a visual
token generator, successfully solving the challenges of high-resolution input
and complex representation learning for text-rich images. Secondly, we enhance
the perception and comprehension abilities of StrucTexTv3 through instruction
learning, seamlessly integrating various text-oriented tasks into a unified
framework. Thirdly, we have curated a comprehensive collection of high-quality
text-rich images, abbreviated as TIM-30M, encompassing diverse scenarios like
incidental scenes, office documents, web pages, and screenshots, thereby
improving the robustness of our model. Our method achieved SOTA results in
text-rich image perception tasks, and significantly improved performance in
comprehension tasks. Among multimodal models with LLM decoder of approximately
1.8B parameters, it stands out as a leader, which also makes the deployment of
edge devices feasible. In summary, the StrucTexTv3 model, featuring efficient
structural design, outstanding performance, and broad adaptability, offers
robust support for diverse intelligent application tasks involving text-rich
images, thus exhibiting immense potential for widespread application.
","['Pengyuan Lyu', 'Yulin Li', 'Hao Zhou', 'Weihong Ma', 'Xingyu Wan', 'Qunyi Xie', 'Liang Wu', 'Chengquan Zhang', 'Kun Yao', 'Errui Ding', 'Jingdong Wang']",2024-05-31T16:55:04Z,11
http://arxiv.org/abs/2405.20987v1,"Early Stopping Criteria for Training Generative Adversarial Networks in
  Biomedical Imaging","  Generative Adversarial Networks (GANs) have high computational costs to train
their complex architectures. Throughout the training process, GANs' output is
analyzed qualitatively based on the loss and synthetic images' diversity and
quality. Based on this qualitative analysis, training is manually halted once
the desired synthetic images are generated. By utilizing an early stopping
criterion, the computational cost and dependence on manual oversight can be
reduced yet impacted by training problems such as mode collapse,
non-convergence, and instability. This is particularly prevalent in biomedical
imagery, where training problems degrade the diversity and quality of synthetic
images, and the high computational cost associated with training makes complex
architectures increasingly inaccessible. This work proposes a novel early
stopping criteria to quantitatively detect training problems, halt training,
and reduce the computational costs associated with synthesizing biomedical
images. Firstly, the range of generator and discriminator loss values is
investigated to assess whether mode collapse, non-convergence, and instability
occur sequentially, concurrently, or interchangeably throughout the training of
GANs. Secondly, utilizing these occurrences in conjunction with the Mean
Structural Similarity Index (MS-SSIM) and Fr\'echet Inception Distance (FID)
scores of synthetic images forms the basis of the proposed early stopping
criteria. This work helps identify the occurrence of training problems in GANs
using low-resource computational cost and reduces training time to generate
diversified and high-quality synthetic images.
","['Muhammad Muneeb Saad', 'Mubashir Husain Rehmani', ""Ruairi O'Reilly""]",2024-05-31T16:33:20Z,3
http://arxiv.org/abs/2405.20986v1,"Uncertainty Quantification for Bird's Eye View Semantic Segmentation:
  Methods and Benchmarks","  The fusion of raw features from multiple sensors on an autonomous vehicle to
create a Bird's Eye View (BEV) representation is crucial for planning and
control systems. There is growing interest in using deep learning models for
BEV semantic segmentation. Anticipating segmentation errors and improving the
explainability of DNNs is essential for autonomous driving, yet it is
under-studied. This paper introduces a benchmark for predictive uncertainty
quantification in BEV segmentation. The benchmark assesses various approaches
across three popular datasets using two representative backbones and focuses on
the effectiveness of predicted uncertainty in identifying misclassified and
out-of-distribution (OOD) pixels, as well as calibration. Empirical findings
highlight the challenges in uncertainty quantification. Our results find that
evidential deep learning based approaches show the most promise by efficiently
quantifying aleatoric and epistemic uncertainty. We propose the
Uncertainty-Focal-Cross-Entropy (UFCE) loss, designed for highly imbalanced
data, which consistently improves the segmentation quality and calibration.
Additionally, we introduce a vacuity-scaled regularization term that enhances
the model's focus on high uncertainty pixels, improving epistemic uncertainty
quantification.
","['Linlin Yu', 'Bowen Yang', 'Tianhao Wang', 'Kangshuo Li', 'Feng Chen']",2024-05-31T16:32:46Z,5
http://arxiv.org/abs/2405.20985v1,"DeCo: Decoupling Token Compression from Semantic Abstraction in
  Multimodal Large Language Models","  The visual projector, which bridges the vision and language modalities and
facilitates cross-modal alignment, serves as a crucial component in MLLMs.
However, measuring the effectiveness of projectors in vision-language alignment
remains under-explored, which currently can only be inferred from the
performance of MLLMs on downstream tasks. Motivated by the problem, this study
examines the projector module by interpreting the vision-language semantic flow
within MLLMs. Specifically, we trace back the semantic relevance flow from
generated language tokens to raw visual encoder patches and the intermediate
outputs produced by projectors. Our findings reveal that compressive projectors
(e.g., QFormer), abstract visual patches into a limited set of semantic
concepts, such as objects or attributes, resulting in a 'double abstraction'
phenomenon. This involves a first visual semantic abstraction by the projector
referring to pre-defined query tokens, and a second extraction by the LLM based
on text instructions. The double abstraction is inefficient in training and
will result in cumulative vision semantics deficiency. To mitigate this issue,
we propose the key insight of 'Decouple Compression from Abstraction (DeCo),
that is compressing the visual token number at the patch level by projectors
and allowing the LLM to handle visual semantic abstraction entirely.
Consequently, we adopt a simple compressor, i.e., 2D Adaptive Pooling, to
downsample visual patches in a parameter-free manner. Empirical evaluation
demonstrates that DeCo surpasses traditional compressive projectors regarding
both performance and efficiency. It achieves performance gains of 0.9%, 7.1%,
and 2.9% across the MLLM Benchmarks, Visual Localization, and Open-ended VQA
tasks with fewer trainable parameters and faster convergence speed.
","['Linli Yao', 'Lei Li', 'Shuhuai Ren', 'Lean Wang', 'Yuanxin Liu', 'Xu Sun', 'Lu Hou']",2024-05-31T16:31:38Z,7
http://arxiv.org/abs/2405.20971v1,"Amortizing intractable inference in diffusion models for vision,
  language, and control","  Diffusion models have emerged as effective distribution estimators in vision,
language, and reinforcement learning, but their use as priors in downstream
tasks poses an intractable posterior inference problem. This paper studies
amortized sampling of the posterior over data, $\mathbf{x}\sim p^{\rm
post}(\mathbf{x})\propto p(\mathbf{x})r(\mathbf{x})$, in a model that consists
of a diffusion generative model prior $p(\mathbf{x})$ and a black-box
constraint or likelihood function $r(\mathbf{x})$. We state and prove the
asymptotic correctness of a data-free learning objective, relative trajectory
balance, for training a diffusion model that samples from this posterior, a
problem that existing methods solve only approximately or in restricted cases.
Relative trajectory balance arises from the generative flow network perspective
on diffusion models, which allows the use of deep reinforcement learning
techniques to improve mode coverage. Experiments illustrate the broad potential
of unbiased inference of arbitrary posteriors under diffusion priors: in vision
(classifier guidance), language (infilling under a discrete diffusion LLM), and
multimodal data (text-to-image generation). Beyond generative modeling, we
apply relative trajectory balance to the problem of continuous control with a
score-based behavior prior, achieving state-of-the-art results on benchmarks in
offline reinforcement learning.
","['Siddarth Venkatraman', 'Moksh Jain', 'Luca Scimeca', 'Minsu Kim', 'Marcin Sendera', 'Mohsin Hasan', 'Luke Rowe', 'Sarthak Mittal', 'Pablo Lemos', 'Emmanuel Bengio', 'Alexandre Adam', 'Jarrid Rector-Brooks', 'Yoshua Bengio', 'Glen Berseth', 'Nikolay Malkin']",2024-05-31T16:18:46Z,15
http://arxiv.org/abs/2405.20881v1,"S4Fusion: Saliency-aware Selective State Space Model for Infrared
  Visible Image Fusion","  As one of the tasks in Image Fusion, Infrared and Visible Image Fusion aims
to integrate complementary information captured by sensors of different
modalities into a single image. The Selective State Space Model (SSSM), known
for its ability to capture long-range dependencies, has demonstrated its
potential in the field of computer vision. However, in image fusion, current
methods underestimate the potential of SSSM in capturing the global spatial
information of both modalities. This limitation prevents the simultaneous
consideration of the global spatial information from both modalities during
interaction, leading to a lack of comprehensive perception of salient targets.
Consequently, the fusion results tend to bias towards one modality instead of
adaptively preserving salient targets. To address this issue, we propose the
Saliency-aware Selective State Space Fusion Model (S4Fusion). In our S4Fusion,
the designed Cross-Modal Spatial Awareness Module (CMSA) can simultaneously
focus on global spatial information from both modalities while facilitating
their interaction, thereby comprehensively capturing complementary information.
Additionally, S4Fusion leverages a pre-trained network to perceive uncertainty
in the fused images. By minimizing this uncertainty, S4Fusion adaptively
highlights salient targets from both images. Extensive experiments demonstrate
that our approach produces high-quality images and enhances performance in
downstream tasks.
","['Haolong Ma', 'Hui Li', 'Chunyang Cheng', 'Gaoang Wang', 'Xiaoning Song', 'Xiaojun Wu']",2024-05-31T14:55:31Z,6
http://arxiv.org/abs/2405.20853v1,MeshXL: Neural Coordinate Field for Generative 3D Foundation Models,"  The polygon mesh representation of 3D data exhibits great flexibility, fast
rendering speed, and storage efficiency, which is widely preferred in various
applications. However, given its unstructured graph representation, the direct
generation of high-fidelity 3D meshes is challenging. Fortunately, with a
pre-defined ordering strategy, 3D meshes can be represented as sequences, and
the generation process can be seamlessly treated as an auto-regressive problem.
In this paper, we validate the Neural Coordinate Field (NeurCF), an explicit
coordinate representation with implicit neural embeddings, is a
simple-yet-effective representation for large-scale sequential mesh modeling.
After that, we present MeshXL, a family of generative pre-trained
auto-regressive models, which addresses the process of 3D mesh generation with
modern large language model approaches. Extensive experiments show that MeshXL
is able to generate high-quality 3D meshes, and can also serve as foundation
models for various down-stream applications.
","['Sijin Chen', 'Xin Chen', 'Anqi Pang', 'Xianfang Zeng', 'Wei Cheng', 'Yijun Fu', 'Fukun Yin', 'Yanru Wang', 'Zhibin Wang', 'Chi Zhang', 'Jingyi Yu', 'Gang Yu', 'Bin Fu', 'Tao Chen']",2024-05-31T14:35:35Z,14
http://arxiv.org/abs/2405.20851v1,MegActor: Harness the Power of Raw Video for Vivid Portrait Animation,"  Despite raw driving videos contain richer information on facial expressions
than intermediate representations such as landmarks in the field of portrait
animation, they are seldom the subject of research. This is due to two
challenges inherent in portrait animation driven with raw videos: 1)
significant identity leakage; 2) Irrelevant background and facial details such
as wrinkles degrade performance. To harnesses the power of the raw videos for
vivid portrait animation, we proposed a pioneering conditional diffusion model
named as MegActor. First, we introduced a synthetic data generation framework
for creating videos with consistent motion and expressions but inconsistent IDs
to mitigate the issue of ID leakage. Second, we segmented the foreground and
background of the reference image and employed CLIP to encode the background
details. This encoded information is then integrated into the network via a
text embedding module, thereby ensuring the stability of the background.
Finally, we further style transfer the appearance of the reference image to the
driving video to eliminate the influence of facial details in the driving
videos. Our final model was trained solely on public datasets, achieving
results comparable to commercial models. We hope this will help the open-source
community.The code is available at
https://github.com/megvii-research/MegFaceAnimate.
","['Shurong Yang', 'Huadong Li', 'Juhao Wu', 'Minhao Jing', 'Linze Li', 'Renhe Ji', 'Jiajun Liang', 'Haoqiang Fan']",2024-05-31T14:33:13Z,8
http://arxiv.org/abs/2405.20834v1,"Retrieval Meets Reasoning: Even High-school Textbook Knowledge Benefits
  Multimodal Reasoning","  Large language models equipped with retrieval-augmented generation (RAG)
represent a burgeoning field aimed at enhancing answering capabilities by
leveraging external knowledge bases. Although the application of RAG with
language-only models has been extensively explored, its adaptation into
multimodal vision-language models remains nascent. Going beyond mere answer
generation, the primary goal of multimodal RAG is to cultivate the models'
ability to reason in response to relevant queries. To this end, we introduce a
novel multimodal RAG framework named RMR (Retrieval Meets Reasoning). The RMR
framework employs a bi-modal retrieval module to identify the most relevant
question-answer pairs, which then serve as scaffolds for the multimodal
reasoning process. This training-free approach not only encourages the model to
engage deeply with the reasoning processes inherent in the retrieved content
but also facilitates the generation of answers that are precise and richly
interpretable. Surprisingly, utilizing solely the ScienceQA dataset, collected
from elementary and high school science curricula, RMR significantly boosts the
performance of various vision-language models across a spectrum of benchmark
datasets, including A-OKVQA, MMBench, and SEED. These outcomes highlight the
substantial potential of our multimodal retrieval and reasoning mechanism to
improve the reasoning capabilities of vision-language models.
","['Cheng Tan', 'Jingxuan Wei', 'Linzhuang Sun', 'Zhangyang Gao', 'Siyuan Li', 'Bihui Yu', 'Ruifeng Guo', 'Stan Z. Li']",2024-05-31T14:23:49Z,8
http://arxiv.org/abs/2405.20810v1,Context-aware Difference Distilling for Multi-change Captioning,"  Multi-change captioning aims to describe complex and coupled changes within
an image pair in natural language. Compared with single-change captioning, this
task requires the model to have higher-level cognition ability to reason an
arbitrary number of changes. In this paper, we propose a novel context-aware
difference distilling (CARD) network to capture all genuine changes for
yielding sentences. Given an image pair, CARD first decouples context features
that aggregate all similar/dissimilar semantics, termed common/difference
context features. Then, the consistency and independence constraints are
designed to guarantee the alignment/discrepancy of common/difference context
features. Further, the common context features guide the model to mine locally
unchanged features, which are subtracted from the pair to distill locally
difference features. Next, the difference context features augment the locally
difference features to ensure that all changes are distilled. In this way, we
obtain an omni-representation of all changes, which is translated into
linguistic sentences by a transformer decoder. Extensive experiments on three
public datasets show CARD performs favourably against state-of-the-art
methods.The code is available at https://github.com/tuyunbin/CARD.
","['Yunbin Tu', 'Liang Li', 'Li Su', 'Zheng-Jun Zha', 'Chenggang Yan', 'Qingming Huang']",2024-05-31T14:07:39Z,6
http://arxiv.org/abs/2405.20764v1,"CoMoFusion: Fast and High-quality Fusion of Infrared and Visible Image
  with Consistency Model","  Generative models are widely utilized to model the distribution of fused
images in the field of infrared and visible image fusion. However, current
generative models based fusion methods often suffer from unstable training and
slow inference speed. To tackle this problem, a novel fusion method based on
consistency model is proposed, termed as CoMoFusion, which can generate the
high-quality images and achieve fast image inference speed. In specific, the
consistency model is used to construct multi-modal joint features in the latent
space with the forward and reverse process. Then, the infrared and visible
features extracted by the trained consistency model are fed into fusion module
to generate the final fused image. In order to enhance the texture and salient
information of fused images, a novel loss based on pixel value selection is
also designed. Extensive experiments on public datasets illustrate that our
method obtains the SOTA fusion performance compared with the existing fusion
methods.
","['Zhiming Meng', 'Hui Li', 'Zeyang Zhang', 'Zhongwei Shen', 'Yunlong Yu', 'Xiaoning Song', 'Xiaojun Wu']",2024-05-31T12:35:06Z,7
http://arxiv.org/abs/2405.20759v1,Information Theoretic Text-to-Image Alignment,"  Diffusion models for Text-to-Image (T2I) conditional generation have seen
tremendous success recently. Despite their success, accurately capturing user
intentions with these models still requires a laborious trial and error
process. This challenge is commonly identified as a model alignment problem, an
issue that has attracted considerable attention by the research community.
Instead of relying on fine-grained linguistic analyses of prompts, human
annotation, or auxiliary vision-language models to steer image generation, in
this work we present a novel method that relies on an information-theoretic
alignment measure. In a nutshell, our method uses self-supervised fine-tuning
and relies on point-wise mutual information between prompts and images to
define a synthetic training set to induce model alignment. Our comparative
analysis shows that our method is on-par or superior to the state-of-the-art,
yet requires nothing but a pre-trained denoising network to estimate MI and a
lightweight fine-tuning strategy.
","['Chao Wang', 'Giulio Franzese', 'Alessandro Finamore', 'Massimo Gallo', 'Pietro Michiardi']",2024-05-31T12:20:02Z,5
http://arxiv.org/abs/2405.20735v1,"Language Augmentation in CLIP for Improved Anatomy Detection on
  Multi-modal Medical Images","  Vision-language models have emerged as a powerful tool for previously
challenging multi-modal classification problem in the medical domain. This
development has led to the exploration of automated image description
generation for multi-modal clinical scans, particularly for radiology report
generation. Existing research has focused on clinical descriptions for specific
modalities or body regions, leaving a gap for a model providing entire-body
multi-modal descriptions. In this paper, we address this gap by automating the
generation of standardized body station(s) and list of organ(s) across the
whole body in multi-modal MR and CT radiological images. Leveraging the
versatility of the Contrastive Language-Image Pre-training (CLIP), we refine
and augment the existing approach through multiple experiments, including
baseline model fine-tuning, adding station(s) as a superset for better
correlation between organs, along with image and language augmentations. Our
proposed approach demonstrates 47.6% performance improvement over baseline
PubMedCLIP.
","['Mansi Kakkar', 'Dattesh Shanbhag', 'Chandan Aladahalli', 'Gurunath Reddy M']",2024-05-31T09:59:11Z,4
http://arxiv.org/abs/2405.20729v1,Extreme Point Supervised Instance Segmentation,"  This paper introduces a novel approach to learning instance segmentation
using extreme points, i.e., the topmost, leftmost, bottommost, and rightmost
points, of each object. These points are readily available in the modern
bounding box annotation process while offering strong clues for precise
segmentation, and thus allows to improve performance at the same annotation
cost with box-supervised methods. Our work considers extreme points as a part
of the true instance mask and propagates them to identify potential foreground
and background points, which are all together used for training a pseudo label
generator. Then pseudo labels given by the generator are in turn used for
supervised learning of our final model. On three public benchmarks, our method
significantly outperforms existing box-supervised methods, further narrowing
the gap with its fully supervised counterpart. In particular, our model
generates high-quality masks when a target object is separated into multiple
parts, where previous box-supervised methods often fail.
","['Hyeonjun Lee', 'Sehyun Hwang', 'Suha Kwak']",2024-05-31T09:37:39Z,3
http://arxiv.org/abs/2405.20720v1,"Power of Cooperative Supervision: Multiple Teachers Framework for
  Enhanced 3D Semi-Supervised Object Detection","  To ensure safe urban driving for autonomous platforms, it is crucial not only
to develop high-performance object detection techniques but also to establish a
diverse and representative dataset that captures various urban environments and
object characteristics. To address these two issues, we have constructed a
multi-class 3D LiDAR dataset reflecting diverse urban environments and object
characteristics, and developed a robust 3D semi-supervised object detection
(SSOD) based on a multiple teachers framework. This SSOD framework categorizes
similar classes and assigns specialized teachers to each category. Through
collaborative supervision among these category-specialized teachers, the
student network becomes increasingly proficient, leading to a highly effective
object detector. We propose a simple yet effective augmentation technique,
Pie-based Point Compensating Augmentation (PieAug), to enable the teacher
network to generate high-quality pseudo-labels. Extensive experiments on the
WOD, KITTI, and our datasets validate the effectiveness of our proposed method
and the quality of our dataset. Experimental results demonstrate that our
approach consistently outperforms existing state-of-the-art 3D semi-supervised
object detection methods across all datasets. We plan to release our
multi-class LiDAR dataset and the source code available on our Github
repository in the near future.
","['Jin-Hee Lee', 'Jae-Keun Lee', 'Je-Seok Kim', 'Soon Kwon']",2024-05-31T09:23:25Z,4
http://arxiv.org/abs/2405.20717v1,Cyclic image generation using chaotic dynamics,"  Successive image generation using cyclic transformations is demonstrated by
extending the CycleGAN model to transform images among three different
categories. Repeated application of the trained generators produces sequences
of images that transition among the different categories. The generated image
sequences occupy a more limited region of the image space compared with the
original training dataset. Quantitative evaluation using precision and recall
metrics indicates that the generated images have high quality but reduced
diversity relative to the training dataset. Such successive generation
processes are characterized as chaotic dynamics in terms of dynamical system
theory. Positive Lyapunov exponents estimated from the generated trajectories
confirm the presence of chaotic dynamics, with the Lyapunov dimension of the
attractor found to be comparable to the intrinsic dimension of the training
data manifold. The results suggest that chaotic dynamics in the image space
defined by the deep generative model contribute to the diversity of the
generated images, constituting a novel approach for multi-class image
generation. This model can be interpreted as an extension of classical
associative memory to perform hetero-association among image categories.
","['Takaya Tanaka', 'Yutaka Yamaguti']",2024-05-31T09:14:36Z,2
http://arxiv.org/abs/2405.20711v1,"Revisiting Mutual Information Maximization for Generalized Category
  Discovery","  Generalized category discovery presents a challenge in a realistic scenario,
which requires the model's generalization ability to recognize unlabeled
samples from known and unknown categories. This paper revisits the challenge of
generalized category discovery through the lens of information maximization
(InfoMax) with a probabilistic parametric classifier. Our findings reveal that
ensuring independence between known and unknown classes while concurrently
assuming a uniform probability distribution across all classes, yields an
enlarged margin among known and unknown classes that promotes the model's
performance. To achieve the aforementioned independence, we propose a novel
InfoMax-based method, Regularized Parametric InfoMax (RPIM), which adopts
pseudo labels to supervise unlabeled samples during InfoMax, while proposing a
regularization to ensure the quality of the pseudo labels. Additionally, we
introduce novel semantic-bias transformation to refine the features from the
pre-trained model instead of direct fine-tuning to rescue the computational
costs. Extensive experiments on six benchmark datasets validate the
effectiveness of our method. RPIM significantly improves the performance
regarding unknown classes, surpassing the state-of-the-art method by an average
margin of 3.5%.
","['Zhaorui Tan', 'Chengrui Zhang', 'Xi Yang', 'Jie Sun', 'Kaizhu Huang']",2024-05-31T09:07:15Z,5
http://arxiv.org/abs/2405.20685v1,"Enhancing Counterfactual Image Generation Using Mahalanobis Distance
  with Distribution Preferences in Feature Space","  In the realm of Artificial Intelligence (AI), the importance of Explainable
Artificial Intelligence (XAI) is increasingly recognized, particularly as AI
models become more integral to our lives. One notable single-instance XAI
approach is counterfactual explanation, which aids users in comprehending a
model's decisions and offers guidance on altering these decisions. Specifically
in the context of image classification models, effective image counterfactual
explanations can significantly enhance user understanding. This paper
introduces a novel method for computing feature importance within the feature
space of a black-box model. By employing information fusion techniques, our
method maximizes the use of data to address feature counterfactual explanations
in the feature space. Subsequently, we utilize an image generation model to
transform these feature counterfactual explanations into image counterfactual
explanations. Our experiments demonstrate that the counterfactual explanations
generated by our method closely resemble the original images in both pixel and
feature spaces. Additionally, our method outperforms established baselines,
achieving impressive experimental results.
","['Yukai Zhang', 'Ao Xu', 'Zihao Li', 'Tieru Wu']",2024-05-31T08:26:53Z,4
http://arxiv.org/abs/2405.20672v1,"Investigating and unmasking feature-level vulnerabilities of CNNs to
  adversarial perturbations","  This study explores the impact of adversarial perturbations on Convolutional
Neural Networks (CNNs) with the aim of enhancing the understanding of their
underlying mechanisms. Despite numerous defense methods proposed in the
literature, there is still an incomplete understanding of this phenomenon.
Instead of treating the entire model as vulnerable, we propose that specific
feature maps learned during training contribute to the overall vulnerability.
To investigate how the hidden representations learned by a CNN affect its
vulnerability, we introduce the Adversarial Intervention framework. Experiments
were conducted on models trained on three well-known computer vision datasets,
subjecting them to attacks of different nature. Our focus centers on the
effects that adversarial perturbations to a model's initial layer have on the
overall behavior of the model. Empirical results revealed compelling insights:
a) perturbing selected channel combinations in shallow layers causes
significant disruptions; b) the channel combinations most responsible for the
disruptions are common among different types of attacks; c) despite shared
vulnerable combinations of channels, different attacks affect hidden
representations with varying magnitudes; d) there exists a positive correlation
between a kernel's magnitude and its vulnerability. In conclusion, this work
introduces a novel framework to study the vulnerability of a CNN model to
adversarial perturbations, revealing insights that contribute to a deeper
understanding of the phenomenon. The identified properties pave the way for the
development of efficient ad-hoc defense mechanisms in future applications.
","['Davide Coppola', 'Hwee Kuan Lee']",2024-05-31T08:14:44Z,2
http://arxiv.org/abs/2405.20669v1,"Fourier123: One Image to High-Quality 3D Object Generation with Hybrid
  Fourier Score Distillation","  Single image-to-3D generation is pivotal for crafting controllable 3D assets.
Given its underconstrained nature, we leverage geometric priors from a 3D novel
view generation diffusion model and appearance priors from a 2D image
generation method to guide the optimization process. We note that a disparity
exists between the training datasets of 2D and 3D diffusion models, leading to
their outputs showing marked differences in appearance. Specifically, 2D models
tend to deliver more detailed visuals, whereas 3D models produce consistent yet
over-smooth results across different views. Hence, we optimize a set of 3D
Gaussians using 3D priors in spatial domain to ensure geometric consistency,
while exploiting 2D priors in the frequency domain through Fourier transform
for higher visual quality. This 2D-3D hybrid Fourier Score Distillation
objective function (dubbed hy-FSD), can be integrated into existing 3D
generation methods, yielding significant performance improvements. With this
technique, we further develop an image-to-3D generation pipeline to create
high-quality 3D objects within one minute, named Fourier123. Extensive
experiments demonstrate that Fourier123 excels in efficient generation with
rapid convergence speed and visual-friendly generation results.
","['Shuzhou Yang', 'Yu Wang', 'Haijie Li', 'Jiarui Meng', 'Xiandong Meng', 'Jian Zhang']",2024-05-31T08:11:25Z,6
http://arxiv.org/abs/2405.20666v1,"MASA: Motion-aware Masked Autoencoder with Semantic Alignment for Sign
  Language Recognition","  Sign language recognition (SLR) has long been plagued by insufficient model
representation capabilities. Although current pre-training approaches have
alleviated this dilemma to some extent and yielded promising performance by
employing various pretext tasks on sign pose data, these methods still suffer
from two primary limitations: 1) Explicit motion information is usually
disregarded in previous pretext tasks, leading to partial information loss and
limited representation capability. 2) Previous methods focus on the local
context of a sign pose sequence, without incorporating the guidance of the
global meaning of lexical signs. To this end, we propose a Motion-Aware masked
autoencoder with Semantic Alignment (MASA) that integrates rich motion cues and
global semantic information in a self-supervised learning paradigm for SLR. Our
framework contains two crucial components, i.e., a motion-aware masked
autoencoder (MA) and a momentum semantic alignment module (SA). Specifically,
in MA, we introduce an autoencoder architecture with a motion-aware masked
strategy to reconstruct motion residuals of masked frames, thereby explicitly
exploring dynamic motion cues among sign pose sequences. Moreover, in SA, we
embed our framework with global semantic awareness by aligning the embeddings
of different augmented samples from the input sequence in the shared latent
space. In this way, our framework can simultaneously learn local motion cues
and global semantic features for comprehensive sign language representation.
Furthermore, we conduct extensive experiments to validate the effectiveness of
our method, achieving new state-of-the-art performance on four public
benchmarks.
","['Weichao Zhao', 'Hezhen Hu', 'Wengang Zhou', 'Yunyao Mao', 'Min Wang', 'Houqiang Li']",2024-05-31T08:06:05Z,6
http://arxiv.org/abs/2405.20650v1,"GenMix: Combining Generative and Mixture Data Augmentation for Medical
  Image Classification","  In this paper, we propose a novel data augmentation technique called GenMix,
which combines generative and mixture approaches to leverage the strengths of
both methods. While generative models excel at creating new data patterns, they
face challenges such as mode collapse in GANs and difficulties in training
diffusion models, especially with limited medical imaging data. On the other
hand, mixture models enhance class boundary regions but tend to favor the major
class in scenarios with class imbalance. To address these limitations, GenMix
integrates both approaches to complement each other. GenMix operates in two
stages: (1) training a generative model to produce synthetic images, and (2)
performing mixup between synthetic and real data. This process improves the
quality and diversity of synthetic data while simultaneously benefiting from
the new pattern learning of generative models and the boundary enhancement of
mixture models. We validate the effectiveness of our method on the task of
classifying focal liver lesions (FLLs) in CT images. Our results demonstrate
that GenMix enhances the performance of various generative models, including
DCGAN, StyleGAN, Textual Inversion, and Diffusion Models. Notably, the proposed
method with Textual Inversion outperforms other methods without fine-tuning
diffusion model on the FLL dataset.
","['Hansang Lee', 'Haeil Lee', 'Helen Hong']",2024-05-31T07:32:31Z,3
http://arxiv.org/abs/2405.20633v1,"Action-OOD: An End-to-End Skeleton-Based Model for Robust
  Out-of-Distribution Human Action Detection","  Human action recognition is a crucial task in computer vision systems.
However, in real-world scenarios, human actions often fall outside the
distribution of training data, requiring a model to both recognize
in-distribution (ID) actions and reject out-of-distribution (OOD) ones. Despite
its importance, there has been limited research on OOD detection in human
actions. Existing works on OOD detection mainly focus on image data with RGB
structure, and many methods are post-hoc in nature. While these methods are
convenient and computationally efficient, they often lack sufficient accuracy
and fail to consider the presence of OOD samples. To address these challenges,
we propose a novel end-to-end skeleton-based model called Action-OOD,
specifically designed for OOD human action detection. Unlike some existing
approaches that may require prior knowledge of existing OOD data distribution,
our model solely utilizes in-distribution (ID) data during the training stage,
effectively mitigating the overconfidence issue prevalent in OOD detection. We
introduce an attention-based feature fusion block, which enhances the model's
capability to recognize unknown classes while preserving classification
accuracy for known classes. Further, we present a novel energy-based loss
function and successfully integrate it with the traditional cross-entropy loss
to maximize the separation of data distributions between ID and OOD. Through
extensive experiments conducted on NTU-RGB+D 60, NTU-RGB+D 120, and
Kinetics-400 datasets, we demonstrate the superior performance of our proposed
approach compared to state-of-the-art methods. Our findings underscore the
effectiveness of classic OOD detection techniques in the context of
skeleton-based action recognition tasks, offering promising avenues for future
research in this field. Code will be available at:
https://github.com/YilliaJing/Action-OOD.git.
","['Jing Xu', 'Anqi Zhu', 'Jingyu Lin', 'Qiuhong Ke', 'Cunjian Chen']",2024-05-31T05:49:37Z,5
http://arxiv.org/abs/2405.20610v1,"Revisiting and Maximizing Temporal Knowledge in Semi-supervised Semantic
  Segmentation","  In semi-supervised semantic segmentation, the Mean Teacher- and
co-training-based approaches are employed to mitigate confirmation bias and
coupling problems. However, despite their high performance, these approaches
frequently involve complex training pipelines and a substantial computational
burden, limiting the scalability and compatibility of these methods. In this
paper, we propose a PrevMatch framework that effectively mitigates the
aforementioned limitations by maximizing the utilization of the temporal
knowledge obtained during the training process. The PrevMatch framework relies
on two core strategies: (1) we reconsider the use of temporal knowledge and
thus directly utilize previous models obtained during training to generate
additional pseudo-label guidance, referred to as previous guidance. (2) we
design a highly randomized ensemble strategy to maximize the effectiveness of
the previous guidance. Experimental results on four benchmark semantic
segmentation datasets confirm that the proposed method consistently outperforms
existing methods across various evaluation protocols. In particular, with
DeepLabV3+ and ResNet-101 network settings, PrevMatch outperforms the existing
state-of-the-art method, Diverse Co-training, by +1.6 mIoU on Pascal VOC with
only 92 annotated images, while achieving 2.4 times faster training.
Furthermore, the results indicate that PrevMatch induces stable optimization,
particularly in benefiting classes that exhibit poor performance. Code is
available at https://github.com/wooseok-shin/PrevMatch
","['Wooseok Shin', 'Hyun Joon Park', 'Jin Sob Kim', 'Sung Won Han']",2024-05-31T03:54:59Z,4
http://arxiv.org/abs/2405.20607v1,"Textual Inversion and Self-supervised Refinement for Radiology Report
  Generation","  Existing mainstream approaches follow the encoder-decoder paradigm for
generating radiology reports. They focus on improving the network structure of
encoders and decoders, which leads to two shortcomings: overlooking the
modality gap and ignoring report content constraints. In this paper, we
proposed Textual Inversion and Self-supervised Refinement (TISR) to address the
above two issues. Specifically, textual inversion can project text and image
into the same space by representing images as pseudo words to eliminate the
cross-modeling gap. Subsequently, self-supervised refinement refines these
pseudo words through contrastive loss computation between images and texts,
enhancing the fidelity of generated reports to images. Notably, TISR is
orthogonal to most existing methods, plug-and-play. We conduct experiments on
two widely-used public datasets and achieve significant improvements on various
baselines, which demonstrates the effectiveness and generalization of TISR. The
code will be available soon.
","['Yuanjiang Luo', 'Hongxiang Li', 'Xuan Wu', 'Meng Cao', 'Xiaoshuang Huang', 'Zhihong Zhu', 'Peixi Liao', 'Hu Chen', 'Yi Zhang']",2024-05-31T03:47:44Z,9
http://arxiv.org/abs/2405.20596v1,"Generalized Semi-Supervised Learning via Self-Supervised Feature
  Adaptation","  Traditional semi-supervised learning (SSL) assumes that the feature
distributions of labeled and unlabeled data are consistent which rarely holds
in realistic scenarios. In this paper, we propose a novel SSL setting, where
unlabeled samples are drawn from a mixed distribution that deviates from the
feature distribution of labeled samples. Under this setting, previous SSL
methods tend to predict wrong pseudo-labels with the model fitted on labeled
data, resulting in noise accumulation. To tackle this issue, we propose
Self-Supervised Feature Adaptation (SSFA), a generic framework for improving
SSL performance when labeled and unlabeled data come from different
distributions. SSFA decouples the prediction of pseudo-labels from the current
model to improve the quality of pseudo-labels. Particularly, SSFA incorporates
a self-supervised task into the SSL framework and uses it to adapt the feature
extractor of the model to the unlabeled data. In this way, the extracted
features better fit the distribution of unlabeled data, thereby generating
high-quality pseudo-labels. Extensive experiments show that our proposed SSFA
is applicable to various pseudo-label-based SSL learners and significantly
improves performance in labeled, unlabeled, and even unseen distributions.
","['Jiachen Liang', 'Ruibing Hou', 'Hong Chang', 'Bingpeng Ma', 'Shiguang Shan', 'Xilin Chen']",2024-05-31T03:13:45Z,6
http://arxiv.org/abs/2405.20790v1,Intersectional Unfairness Discovery,"  AI systems have been shown to produce unfair results for certain subgroups of
population, highlighting the need to understand bias on certain sensitive
attributes. Current research often falls short, primarily focusing on the
subgroups characterized by a single sensitive attribute, while neglecting the
nature of intersectional fairness of multiple sensitive attributes. This paper
focuses on its one fundamental aspect by discovering diverse high-bias
subgroups under intersectional sensitive attributes. Specifically, we propose a
Bias-Guided Generative Network (BGGN). By treating each bias value as a reward,
BGGN efficiently generates high-bias intersectional sensitive attributes.
Experiments on real-world text and image datasets demonstrate a diverse and
efficient discovery of BGGN. To further evaluate the generated unseen but
possible unfair intersectional sensitive attributes, we formulate them as
prompts and use modern generative AI to produce new texts and images. The
results of frequently generating biased data provides new insights of
discovering potential unfairness in popular modern generative AI systems.
Warning: This paper contains generative examples that are offensive in nature.
","['Gezheng Xu', 'Qi Chen', 'Charles Ling', 'Boyu Wang', 'Changjian Shui']",2024-05-31T13:45:52Z,5
http://arxiv.org/abs/2405.21004v1,"MunchSonic: Tracking Fine-grained Dietary Actions through Active
  Acoustic Sensing on Eyeglasses","  We introduce MunchSonic, an AI-powered active acoustic sensing system
integrated into eyeglasses, designed to track fine-grained dietary actions like
hand-to-mouth movements for food intake, chewing, and drinking. MunchSonic
emits inaudible ultrasonic waves from a commodity eyeglass frame. The reflected
signals contain rich information about the position and movements of various
body parts, including the mouth, jaw, arms, and hands, all of which are
involved in eating activities. These signals are then processed by a custom
deep-learning pipeline to classify six actions: food intake, chewing, drinking,
talking, face-hand touching, and other activities (null). In an unconstrained
user study with 12 participants, MunchSonic achieves a 93.5% macro F1-score in
a user-independent evaluation with a 2-second time resolution, demonstrating
its effectiveness. Additionally, MunchSonic accurately tracks eating episodes
and the frequency of food intake within those episodes.
","['Saif Mahmud', 'Devansh Agarwal', 'Ashwin Ajit', 'Qikang Liang', 'Thalia Viranda', 'Francois Guimbretiere', 'Cheng Zhang']",2024-05-31T16:44:54Z,7
http://arxiv.org/abs/2405.21061v1,Graph External Attention Enhanced Transformer,"  The Transformer architecture has recently gained considerable attention in
the field of graph representation learning, as it naturally overcomes several
limitations of Graph Neural Networks (GNNs) with customized attention
mechanisms or positional and structural encodings. Despite making some
progress, existing works tend to overlook external information of graphs,
specifically the correlation between graphs. Intuitively, graphs with similar
structures should have similar representations. Therefore, we propose Graph
External Attention (GEA) -- a novel attention mechanism that leverages multiple
external node/edge key-value units to capture inter-graph correlations
implicitly. On this basis, we design an effective architecture called Graph
External Attention Enhanced Transformer (GEAET), which integrates local
structure and global interaction information for more comprehensive graph
representations. Extensive experiments on benchmark datasets demonstrate that
GEAET achieves state-of-the-art empirical performance. The source code is
available for reproducibility at: https://github.com/icm1018/GEAET.
","['Jianqing Liang', 'Min Chen', 'Jiye Liang']",2024-05-31T17:50:27Z,3
http://arxiv.org/abs/2405.21060v1,"Transformers are SSMs: Generalized Models and Efficient Algorithms
  Through Structured State Space Duality","  While Transformers have been the main architecture behind deep learning's
success in language modeling, state-space models (SSMs) such as Mamba have
recently been shown to match or outperform Transformers at small to medium
scale. We show that these families of models are actually quite closely
related, and develop a rich framework of theoretical connections between SSMs
and variants of attention, connected through various decompositions of a
well-studied class of structured semiseparable matrices. Our state space
duality (SSD) framework allows us to design a new architecture (Mamba-2) whose
core layer is an a refinement of Mamba's selective SSM that is 2-8X faster,
while continuing to be competitive with Transformers on language modeling.
","['Tri Dao', 'Albert Gu']",2024-05-31T17:50:01Z,2
http://arxiv.org/abs/2405.20954v1,"Aligning Multiclass Neural Network Classifier Criterion with Task
  Performance via $F_β$-Score","  Multiclass neural network classifiers are typically trained using
cross-entropy loss. Following training, the performance of this same neural
network is evaluated using an application-specific metric based on the
multiclass confusion matrix, such as the Macro $F_\beta$-Score. It is
questionable whether the use of cross-entropy will yield a classifier that
aligns with the intended application-specific performance criteria,
particularly in scenarios where there is a need to emphasize one aspect of
classifier performance. For example, if greater precision is preferred over
recall, the $\beta$ value in the $F_\beta$ evaluation metric can be adjusted
accordingly, but the cross-entropy objective remains unaware of this preference
during training. We propose a method that addresses this training-evaluation
gap for multiclass neural network classifiers such that users can train these
models informed by the desired final $F_\beta$-Score. Following prior work in
binary classification, we utilize the concepts of the soft-set confusion
matrices and a piecewise-linear approximation of the Heaviside step function.
Our method extends the $2 \times 2$ binary soft-set confusion matrix to a
multiclass $d \times d$ confusion matrix and proposes dynamic adaptation of the
threshold value $\tau$, which parameterizes the piecewise-linear Heaviside
approximation during run-time. We present a theoretical analysis that shows
that our method can be used to optimize for a soft-set based approximation of
Macro-$F_\beta$ that is a consistent estimator of Macro-$F_\beta$, and our
extensive experiments show the practical effectiveness of our approach.
","['Nathan Tsoi', 'Deyuan Li', 'Taesoo Daniel Lee', 'Marynel Vázquez']",2024-05-31T15:54:01Z,4
http://arxiv.org/abs/2405.20879v1,Flow matching achieves minimax optimal convergence,"  Flow matching (FM) has gained significant attention as a simulation-free
generative model. Unlike diffusion models, which are based on stochastic
differential equations, FM employs a simpler approach by solving an ordinary
differential equation with an initial condition from a normal distribution,
thus streamlining the sample generation process. This paper discusses the
convergence properties of FM in terms of the $p$-Wasserstein distance, a
measure of distributional discrepancy. We establish that FM can achieve the
minmax optimal convergence rate for $1 \leq p \leq 2$, presenting the first
theoretical evidence that FM can reach convergence rates comparable to those of
diffusion models. Our analysis extends existing frameworks by examining a
broader class of mean and variance functions for the vector fields and
identifies specific conditions necessary to attain these optimal rates.
","['Kenji Fukumizu', 'Taiji Suzuki', 'Noboru Isobe', 'Kazusato Oko', 'Masanori Koyama']",2024-05-31T14:54:51Z,5
http://arxiv.org/abs/2405.20799v1,"Rough Transformers: Lightweight Continuous-Time Sequence Modelling with
  Path Signatures","  Time-series data in real-world settings typically exhibit long-range
dependencies and are observed at non-uniform intervals. In these settings,
traditional sequence-based recurrent models struggle. To overcome this,
researchers often replace recurrent architectures with Neural ODE-based models
to account for irregularly sampled data and use Transformer-based architectures
to account for long-range dependencies. Despite the success of these two
approaches, both incur very high computational costs for input sequences of
even moderate length. To address this challenge, we introduce the Rough
Transformer, a variation of the Transformer model that operates on
continuous-time representations of input sequences and incurs significantly
lower computational costs. In particular, we propose \textit{multi-view
signature attention}, which uses path signatures to augment vanilla attention
and to capture both local and global (multi-scale) dependencies in the input
data, while remaining robust to changes in the sequence length and sampling
frequency and yielding improved spatial processing. We find that, on a variety
of time-series-related tasks, Rough Transformers consistently outperform their
vanilla attention counterparts while obtaining the representational benefits of
Neural ODE-based models, all at a fraction of the computational time and memory
resources.
","['Fernando Moreno-Pino', 'Álvaro Arroyo', 'Harrison Waldon', 'Xiaowen Dong', 'Álvaro Cartea']",2024-05-31T14:00:44Z,5
http://arxiv.org/abs/2405.20724v1,Learning on Large Graphs using Intersecting Communities,"  Message Passing Neural Networks (MPNNs) are a staple of graph machine
learning. MPNNs iteratively update each node's representation in an input graph
by aggregating messages from the node's neighbors, which necessitates a memory
complexity of the order of the number of graph edges. This complexity might
quickly become prohibitive for large graphs provided they are not very sparse.
In this paper, we propose a novel approach to alleviate this problem by
approximating the input graph as an intersecting community graph (ICG) -- a
combination of intersecting cliques. The key insight is that the number of
communities required to approximate a graph does not depend on the graph size.
We develop a new constructive version of the Weak Graph Regularity Lemma to
efficiently construct an approximating ICG for any input graph. We then devise
an efficient graph learning algorithm operating directly on ICG in linear
memory and time with respect to the number of nodes (rather than edges). This
offers a new and fundamentally different pipeline for learning on very large
non-sparse graphs, whose applicability is demonstrated empirically on node
classification tasks and spatio-temporal data processing.
","['Ben Finkelshtein', 'İsmail İlkan Ceylan', 'Michael Bronstein', 'Ron Levie']",2024-05-31T09:26:26Z,4
http://arxiv.org/abs/2405.20677v1,"Provably Efficient Interactive-Grounded Learning with Personalized
  Reward","  Interactive-Grounded Learning (IGL) [Xie et al., 2021] is a powerful
framework in which a learner aims at maximizing unobservable rewards through
interacting with an environment and observing reward-dependent feedback on the
taken actions. To deal with personalized rewards that are ubiquitous in
applications such as recommendation systems, Maghakian et al. [2022] study a
version of IGL with context-dependent feedback, but their algorithm does not
come with theoretical guarantees. In this work, we consider the same problem
and provide the first provably efficient algorithms with sublinear regret under
realizability. Our analysis reveals that the step-function estimator of prior
work can deviate uncontrollably due to finite-sample effects. Our solution is a
novel Lipschitz reward estimator which underestimates the true reward and
enjoys favorable generalization performances. Building on this estimator, we
propose two algorithms, one based on explore-then-exploit and the other based
on inverse-gap weighting. We apply IGL to learning from image feedback and
learning from text feedback, which are reward-free settings that arise in
practice. Experimental results showcase the importance of using our Lipschitz
reward estimator and the overall effectiveness of our algorithms.
","['Mengxiao Zhang', 'Yuheng Zhang', 'Haipeng Luo', 'Paul Mineiro']",2024-05-31T08:21:09Z,4
http://arxiv.org/abs/2405.20664v1,"Weak Robust Compatibility Between Learning Algorithms and Counterfactual
  Explanation Generation Algorithms","  Counterfactual explanation generation is a powerful method for Explainable
Artificial Intelligence. It can help users understand why machine learning
models make specific decisions, and how to change those decisions. Evaluating
the robustness of counterfactual explanation algorithms is therefore crucial.
Previous literature has widely studied the robustness based on the perturbation
of input instances. However, the robustness defined from the perspective of
perturbed instances is sometimes biased, because this definition ignores the
impact of learning algorithms on robustness. In this paper, we propose a more
reasonable definition, Weak Robust Compatibility, based on the perspective of
explanation strength. In practice, we propose WRC-Test to help us generate more
robust counterfactuals. Meanwhile, we designed experiments to verify the
effectiveness of WRC-Test. Theoretically, we introduce the concepts of PAC
learning theory and define the concept of PAC WRC-Approximability. Based on
reasonable assumptions, we establish oracle inequalities about weak robustness,
which gives a sufficient condition for PAC WRC-Approximability.
","['Ao Xu', 'Tieru Wu']",2024-05-31T08:03:52Z,2
http://arxiv.org/abs/2405.20568v1,"Generative AI for Deep Reinforcement Learning: Framework, Analysis, and
  Use Cases","  As a form of artificial intelligence (AI) technology based on interactive
learning, deep reinforcement learning (DRL) has been widely applied across
various fields and has achieved remarkable accomplishments. However, DRL faces
certain limitations, including low sample efficiency and poor generalization.
Therefore, we present how to leverage generative AI (GAI) to address these
issues above and enhance the performance of DRL algorithms in this paper. We
first introduce several classic GAI and DRL algorithms and demonstrate the
applications of GAI-enhanced DRL algorithms. Then, we discuss how to use GAI to
improve DRL algorithms from the data and policy perspectives. Subsequently, we
introduce a framework that demonstrates an actual and novel integration of GAI
with DRL, i.e., GAI-enhanced DRL. Additionally, we provide a case study of the
framework on UAV-assisted integrated near-field/far-field communication to
validate the performance of the proposed framework. Moreover, we present
several future directions. Finally, the related code is available at:
https://xiewenwen22.github.io/GAI-enhanced-DRL.
","['Geng Sun', 'Wenwen Xie', 'Dusit Niyato', 'Fang Mei', 'Jiawen Kang', 'Hongyang Du', 'Shiwen Mao']",2024-05-31T01:25:40Z,7
http://arxiv.org/abs/2405.20983v1,"Goal-Oriented Sensor Reporting Scheduling for Non-linear Dynamic System
  Monitoring","  Goal-oriented communication (GoC) is a form of semantic communication where
the effectiveness of information transmission is measured by its impact on
achieving the desired goal. In the context of the Internet of Things (IoT), GoC
can make IoT sensors to selectively transmit data pertinent to the intended
goals of the receiver. Therefore, GoC holds significant value for IoT networks
as it facilitates timely decision-making at the receiver, reduces network
congestion, and enhances spectral efficiency. In this paper, we consider a
scenario where an edge node polls sensors monitoring the state of a non-linear
dynamic system (NLDS) to respond to the queries of several clients. Our work
delves into the foregoing GoC problem, which we term goal-oriented scheduling
(GoS). Our proposed GoS utilizes deep reinforcement learning (DRL) with
meticulously devised action space, state space, and reward function. The
devised action space and reward function play a pivotal role in reducing the
number of sensor transmissions. Meanwhile, the devised state space empowers our
DRL scheduler to poll the sensor whose observation is expected to minimize the
mean square error (MSE) of the query responses. Our numerical analysis
demonstrates that the proposed GoS can either effectively minimize the query
response MSE further or obtain a resembling MSE compared to benchmark
scheduling methods, depending on the type of query. Furthermore, the proposed
GoS proves to be energy-efficient for the sensors and of lower complexity
compared to benchmark scheduling methods.
","['Prasoon Raghuwanshi', 'Onel Luis Alcaraz López', 'Vimal Bhatia', 'Matti Latva-aho']",2024-05-31T16:29:08Z,4
